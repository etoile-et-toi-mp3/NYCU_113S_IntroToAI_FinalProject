#!/usr/bin/env python3
"""
æ™‚å°šAIåˆ†é¡æº–ç¢ºç‡æ¸¬è©¦ç³»çµ±
æ¸¬è©¦ä¸åŒbackboneæ¨¡å‹çš„åˆ†é¡æº–ç¢ºç‡ä¸¦ç”Ÿæˆè©³ç´°å ±å‘Š
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
import timm
from transformers import ViTModel, ViTConfig
from PIL import Image
import numpy as np
import os
import json
import csv
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import argparse
from collections import defaultdict
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# ==================== è¨­å‚™å„ªåŒ–è¨­ç½® ====================

def setup_device(platform="auto"):
    """è¨­ç½®è¨ˆç®—è¨­å‚™"""
    if platform == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"âœ… ä½¿ç”¨ CUDA: {torch.cuda.get_device_name(0)}")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = torch.device("mps")
            print("âœ… ä½¿ç”¨ Metal Performance Shaders (MPS)")
        else:
            device = torch.device("cpu")
            print("ğŸ’» ä½¿ç”¨ CPU")
    elif platform == "cuda":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    elif platform == "mps":
        device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    else:
        device = torch.device("cpu")
    
    return device

# ==================== æ¨¡å‹æ¶æ§‹å®šç¾© ====================

class FashionBackbone(nn.Module):
    """Fashion Backboneï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰"""
    def __init__(self, backbone_type='mobilenet', pretrained=True):
        super(FashionBackbone, self).__init__()
        self.backbone_type = backbone_type
        
        if backbone_type == 'mobilenet':
            self.backbone = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1 if pretrained else None)
            self.backbone.classifier = nn.Identity()
            self.feature_dim = 960
            
        elif backbone_type == 'resnet18':
            self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)
            self.backbone.fc = nn.Identity()
            self.feature_dim = 512
            
        elif backbone_type == 'resnet50':
            self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)
            self.backbone.fc = nn.Identity()
            self.feature_dim = 2048
            
        elif backbone_type == 'efficientnet_b0':
            self.backbone = timm.create_model('efficientnet_b0', pretrained=pretrained, num_classes=0)
            self.feature_dim = 1280
            
        elif backbone_type == 'efficientnet_b2':
            self.backbone = timm.create_model('efficientnet_b2', pretrained=pretrained, num_classes=0)
            self.feature_dim = 1408
            
        elif backbone_type == 'vit_tiny':
            if pretrained:
                self.backbone = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=0)
            else:
                config = ViTConfig(hidden_size=192, num_hidden_layers=12, num_attention_heads=3)
                self.backbone = ViTModel(config)
            self.feature_dim = 192
            
        elif backbone_type == 'vit_small':
            if pretrained:
                self.backbone = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=0)
            else:
                config = ViTConfig(hidden_size=384, num_hidden_layers=12, num_attention_heads=6)
                self.backbone = ViTModel(config)
            self.feature_dim = 384
            
        elif backbone_type == 'fashion_resnet':
            self.backbone = self._create_fashion_resnet(pretrained)
            self.feature_dim = 512
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„backboneé¡å‹: {backbone_type}")
    
    def _create_fashion_resnet(self, pretrained):
        base_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)
        base_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        base_model.maxpool = nn.Identity()
        base_model.fc = nn.Identity()
        return base_model
    
    def forward(self, x):
        if 'vit' in self.backbone_type and hasattr(self.backbone, 'last_hidden_state'):
            outputs = self.backbone(x)
            if hasattr(outputs, 'last_hidden_state'):
                return outputs.last_hidden_state[:, 0, :]
            else:
                return outputs
        else:
            return self.backbone(x)
    
    def get_feature_dim(self):
        return self.feature_dim

class EnhancedStyleClassifier(nn.Module):
    """å¢å¼·é¢¨æ ¼åˆ†é¡å™¨"""
    def __init__(self, backbone_type='mobilenet', num_styles=11, num_genders=2, feature_dim=1024):
        super(EnhancedStyleClassifier, self).__init__()
        
        self.backbone = FashionBackbone(
            backbone_type=backbone_type, 
            pretrained=True
        )
        
        backbone_features = self.backbone.get_feature_dim()
        self.feature_dim = feature_dim
        
        # ç‰¹å¾µæŠ•å½±å±¤
        self.feature_projection = nn.Sequential(
            nn.Linear(backbone_features, feature_dim),
            nn.LayerNorm(feature_dim),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # é¢¨æ ¼åˆ†é¡é ­
        self.style_classifier = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.LayerNorm(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_styles)
        )
        
        # æ€§åˆ¥åˆ†é¡é ­
        self.gender_classifier = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.LayerNorm(128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_genders)
        )
        
        # æŠ•å½±é ­ï¼ˆç”¨æ–¼å°æ¯”å­¸ç¿’ï¼‰
        self.projection_head = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.LayerNorm(256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.LayerNorm(128)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, (nn.BatchNorm1d, nn.LayerNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
        
    def forward(self, x):
        batch_size = x.size(0)
        if batch_size == 1 and self.training:
            self.eval()
            backbone_features = self.backbone(x)
            features = self.feature_projection(backbone_features)
            
            projected_features = self.projection_head(features)
            projected_features = F.normalize(projected_features, dim=1)
            
            style_logits = self.style_classifier(features)
            gender_logits = self.gender_classifier(features)
            
            self.train()
        else:
            backbone_features = self.backbone(x)
            features = self.feature_projection(backbone_features)
            
            projected_features = self.projection_head(features)
            projected_features = F.normalize(projected_features, dim=1)
            
            style_logits = self.style_classifier(features)
            gender_logits = self.gender_classifier(features)
        
        return {
            'features': features,
            'projected_features': projected_features,
            'style_logits': style_logits,
            'gender_logits': gender_logits
        }

# ==================== æ¸¬è©¦æ•¸æ“šè¼‰å…¥ ====================

class TestDataLoader:
    """æ¸¬è©¦æ•¸æ“šè¼‰å…¥å™¨"""
    def __init__(self, test_data_dir):
        self.test_data_dir = test_data_dir
        self.style_categories = [
            'Artsy', 'Athleisure', 'BRITISH', 'CASUAL', 'GOTH', 'Japanese',
            'Kawaii', 'Korean', 'Preppy', 'STREET', 'Vintage'
        ]
        self.gender_categories = ['MEN', 'WOMEN']
        
        # å‰µå»ºé¡åˆ¥åˆ°ç´¢å¼•çš„æ˜ å°„
        all_categories = []
        for style in sorted(self.style_categories):
            for gender in sorted(self.gender_categories):
                all_categories.append(f"{style}_{gender}")
        
        self.category_to_idx = {cat: idx for idx, cat in enumerate(all_categories)}
        self.idx_to_category = {idx: cat for cat, idx in self.category_to_idx.items()}
        
        # è¼‰å…¥æ¸¬è©¦æ•¸æ“š
        self.test_images = self._load_test_images()
        
    def _load_test_images(self):
        """è¼‰å…¥æ¸¬è©¦åœ–ç‰‡"""
        test_images = []
        
        if not os.path.exists(self.test_data_dir):
            raise ValueError(f"æ¸¬è©¦æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {self.test_data_dir}")
        
        # æŒ‰é¡åˆ¥åç¨±æ’åºæƒæåœ–ç‰‡
        all_files = []
        for filename in os.listdir(self.test_data_dir):
            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                all_files.append(filename)
        
        # æŒ‰æª”åæ’åº
        all_files.sort()
        
        for filename in all_files:
            # è§£ææª”åç²å–é¡åˆ¥
            category = self._parse_category_from_filename(filename)
            if category and category in self.category_to_idx:
                file_path = os.path.join(self.test_data_dir, filename)
                test_images.append({
                    'path': file_path,
                    'filename': filename,
                    'category': category,
                    'category_idx': self.category_to_idx[category],
                    'style': category.split('_')[0],
                    'gender': category.split('_')[1]
                })
        
        print(f"ğŸ“Š è¼‰å…¥äº† {len(test_images)} å¼µæ¸¬è©¦åœ–ç‰‡")
        
        # çµ±è¨ˆæ¯å€‹é¡åˆ¥çš„åœ–ç‰‡æ•¸é‡
        category_counts = defaultdict(int)
        for img in test_images:
            category_counts[img['category']] += 1
        
        print("ğŸ“ˆ å„é¡åˆ¥æ¸¬è©¦åœ–ç‰‡æ•¸é‡:")
        for category in sorted(category_counts.keys()):
            print(f"  {category}: {category_counts[category]} å¼µ")
        
        return test_images
    
    def _parse_category_from_filename(self, filename):
        """å¾æª”åè§£æé¡åˆ¥"""
        # ç§»é™¤å‰¯æª”å
        base_name = os.path.splitext(filename)[0]
        
        # å˜—è©¦åŒ¹é…å·²çŸ¥çš„é¡åˆ¥æ¨¡å¼
        for style in self.style_categories:
            for gender in self.gender_categories:
                category = f"{style}_{gender}"
                if base_name.startswith(category):
                    return category
        
        # å¦‚æœæ²’æœ‰ç›´æ¥åŒ¹é…ï¼Œå˜—è©¦å…¶ä»–è§£ææ–¹å¼
        parts = base_name.split('_')
        if len(parts) >= 2:
            potential_style = parts[0]
            potential_gender = parts[1]
            
            if potential_style in self.style_categories and potential_gender in self.gender_categories:
                return f"{potential_style}_{potential_gender}"
        
        print(f"âš ï¸ ç„¡æ³•è§£ææª”åçš„é¡åˆ¥: {filename}")
        return None

# ==================== æ¨¡å‹æ¸¬è©¦å™¨ ====================

class ModelTester:
    """æ¨¡å‹æ¸¬è©¦å™¨"""
    def __init__(self, device):
        self.device = device
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def load_model(self, model_path, backbone_type):
        """è¼‰å…¥æ¨¡å‹"""
        print(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹: {model_path}")
        
        # å‰µå»ºæ¨¡å‹
        model = EnhancedStyleClassifier(
            backbone_type=backbone_type,
            num_styles=11,
            num_genders=2,
            feature_dim=1024
        )
        
        try:
            # è¼‰å…¥æ¬Šé‡
            checkpoint = torch.load(model_path, map_location=self.device)
            
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
                epoch = checkpoint.get('epoch', 'æœªçŸ¥')
                print(f"âœ… è¼‰å…¥checkpointï¼Œepoch: {epoch}")
            else:
                model.load_state_dict(checkpoint)
                print("âœ… è¼‰å…¥state_dict")
            
            model.to(self.device)
            model.eval()
            
            return model
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            raise
    
    def predict_image(self, model, image_path):
        """é æ¸¬å–®å¼µåœ–ç‰‡"""
        try:
            # è¼‰å…¥å’Œé è™•ç†åœ–ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = model(input_tensor)
                
                # ç²å–é æ¸¬çµæœ
                style_logits = outputs['style_logits']
                gender_logits = outputs['gender_logits']
                
                style_probs = F.softmax(style_logits, dim=1)
                gender_probs = F.softmax(gender_logits, dim=1)
                
                predicted_style_idx = torch.argmax(style_probs, dim=1).item()
                predicted_gender_idx = torch.argmax(gender_probs, dim=1).item()
                
                style_confidence = style_probs[0][predicted_style_idx].item()
                gender_confidence = gender_probs[0][predicted_gender_idx].item()
                
                return {
                    'predicted_style_idx': predicted_style_idx,
                    'predicted_gender_idx': predicted_gender_idx,
                    'style_confidence': style_confidence,
                    'gender_confidence': gender_confidence,
                    'style_probs': style_probs.cpu().numpy()[0],
                    'gender_probs': gender_probs.cpu().numpy()[0]
                }
                
        except Exception as e:
            print(f"âŒ é æ¸¬å¤±æ•— {image_path}: {e}")
            return None
    
    def test_model(self, model, test_data_loader, backbone_type):
        """æ¸¬è©¦æ¨¡å‹æº–ç¢ºç‡"""
        print(f"ğŸ§ª é–‹å§‹æ¸¬è©¦ {backbone_type} æ¨¡å‹...")
        
        results = {
            'backbone': backbone_type,
            'total_images': len(test_data_loader.test_images),
            'correct_predictions': 0,
            'style_correct': 0,
            'gender_correct': 0,
            'category_results': defaultdict(lambda: {'total': 0, 'correct': 0}),
            'detailed_results': [],
            'confusion_matrix_data': []
        }
        
        style_categories = test_data_loader.style_categories
        gender_categories = test_data_loader.gender_categories
        
        for i, test_image in enumerate(test_data_loader.test_images):
            print(f"  è™•ç† {i+1}/{len(test_data_loader.test_images)}: {test_image['filename']}")
            
            # é æ¸¬
            prediction = self.predict_image(model, test_image['path'])
            if prediction is None:
                continue
            
            # çœŸå¯¦æ¨™ç±¤
            true_style = test_image['style']
            true_gender = test_image['gender']
            true_style_idx = style_categories.index(true_style)
            true_gender_idx = gender_categories.index(true_gender)
            
            # é æ¸¬æ¨™ç±¤
            pred_style_idx = prediction['predicted_style_idx']
            pred_gender_idx = prediction['predicted_gender_idx']
            pred_style = style_categories[pred_style_idx]
            pred_gender = gender_categories[pred_gender_idx]
            
            # åˆ¤æ–·æº–ç¢ºæ€§
            style_correct = (pred_style_idx == true_style_idx)
            gender_correct = (pred_gender_idx == true_gender_idx)
            overall_correct = style_correct and gender_correct
            
            # æ›´æ–°çµ±è¨ˆ
            if style_correct:
                results['style_correct'] += 1
            if gender_correct:
                results['gender_correct'] += 1
            if overall_correct:
                results['correct_predictions'] += 1
            
            # é¡åˆ¥çµ±è¨ˆ
            category = test_image['category']
            results['category_results'][category]['total'] += 1
            if overall_correct:
                results['category_results'][category]['correct'] += 1
            
            # è©³ç´°çµæœ
            detail = {
                'filename': test_image['filename'],
                'true_category': category,
                'true_style': true_style,
                'true_gender': true_gender,
                'pred_style': pred_style,
                'pred_gender': pred_gender,
                'style_correct': style_correct,
                'gender_correct': gender_correct,
                'overall_correct': overall_correct,
                'style_confidence': prediction['style_confidence'],
                'gender_confidence': prediction['gender_confidence']
            }
            results['detailed_results'].append(detail)
            
            # æ··æ·†çŸ©é™£æ•¸æ“š
            results['confusion_matrix_data'].append({
                'true_category_idx': test_image['category_idx'],
                'pred_category_idx': pred_style_idx * 2 + pred_gender_idx,  # ç°¡åŒ–çš„çµ„åˆç´¢å¼•
                'true_style_idx': true_style_idx,
                'pred_style_idx': pred_style_idx,
                'true_gender_idx': true_gender_idx,
                'pred_gender_idx': pred_gender_idx
            })
        
        # è¨ˆç®—æº–ç¢ºç‡
        total = results['total_images']
        results['overall_accuracy'] = results['correct_predictions'] / total if total > 0 else 0
        results['style_accuracy'] = results['style_correct'] / total if total > 0 else 0
        results['gender_accuracy'] = results['gender_correct'] / total if total > 0 else 0
        
        print(f"âœ… {backbone_type} æ¸¬è©¦å®Œæˆ")
        print(f"ğŸ“Š æ•´é«”æº–ç¢ºç‡: {results['overall_accuracy']:.4f} ({results['correct_predictions']}/{total})")
        print(f"ğŸ¨ é¢¨æ ¼æº–ç¢ºç‡: {results['style_accuracy']:.4f} ({results['style_correct']}/{total})")
        print(f"ğŸ‘¤ æ€§åˆ¥æº–ç¢ºç‡: {results['gender_accuracy']:.4f} ({results['gender_correct']}/{total})")
        
        return results

# ==================== çµæœåˆ†æå’Œè¦–è¦ºåŒ– ====================

class ResultAnalyzer:
    """çµæœåˆ†æå™¨"""
    def __init__(self, output_dir="test_results"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # å‰µå»ºæ—¥èªŒæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = os.path.join(output_dir, f"test_log_{timestamp}.txt")
        self.csv_file = os.path.join(output_dir, f"accuracy_results_{timestamp}.csv")
        
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write(f"åˆ†é¡æº–ç¢ºç‡æ¸¬è©¦æ—¥èªŒ\n")
            f.write(f"é–‹å§‹æ™‚é–“: {datetime.now().isoformat()}\n")
            f.write("="*80 + "\n")
    
    def log_message(self, message):
        """è¨˜éŒ„æ—¥èªŒ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_msg + "\n")
    
    def save_results_to_csv(self, all_results):
        """ä¿å­˜çµæœåˆ°CSV"""
        self.log_message(f"ğŸ’¾ ä¿å­˜çµæœåˆ°CSV: {self.csv_file}")
        
        # æº–å‚™CSVæ•¸æ“š
        csv_data = []
        for result in all_results:
            row = {
                'Backbone': result['backbone'],
                'Overall_Accuracy': result['overall_accuracy'],
                'Style_Accuracy': result['style_accuracy'],
                'Gender_Accuracy': result['gender_accuracy'],
                'Total_Images': result['total_images'],
                'Correct_Predictions': result['correct_predictions'],
                'Style_Correct': result['style_correct'],
                'Gender_Correct': result['gender_correct']
            }
            
            # æ·»åŠ æ¯å€‹é¡åˆ¥çš„æº–ç¢ºç‡
            for category, cat_result in result['category_results'].items():
                category_accuracy = cat_result['correct'] / cat_result['total'] if cat_result['total'] > 0 else 0
                row[f'{category}_Accuracy'] = category_accuracy
                row[f'{category}_Correct'] = cat_result['correct']
                row[f'{category}_Total'] = cat_result['total']
            
            csv_data.append(row)
        
        # ä¿å­˜åˆ°CSV
        df = pd.DataFrame(csv_data)
        df.to_csv(self.csv_file, index=False, encoding='utf-8-sig')
        
        self.log_message(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {self.csv_file}")
        return self.csv_file
    
    def create_visualizations(self, all_results):
        """å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨"""
        self.log_message("ğŸ“Š é–‹å§‹å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨...")
        
        # è¨­ç½®ä¸­æ–‡å­—é«”
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. æ•´é«”æº–ç¢ºç‡æ¯”è¼ƒ
        self._plot_overall_accuracy(all_results)
        
        # 2. å„é¡åˆ¥æº–ç¢ºç‡ç†±åŠ›åœ–
        self._plot_category_heatmap(all_results)
        
        # 3. é¢¨æ ¼vsæ€§åˆ¥æº–ç¢ºç‡æ•£ä½ˆåœ–
        self._plot_style_gender_scatter(all_results)
        
        # 4. è©³ç´°æº–ç¢ºç‡æŸ±ç‹€åœ–
        self._plot_detailed_accuracy_bars(all_results)
        
        self.log_message("âœ… è¦–è¦ºåŒ–åœ–è¡¨å‰µå»ºå®Œæˆ")
    
    def _plot_overall_accuracy(self, all_results):
        """ç¹ªè£½æ•´é«”æº–ç¢ºç‡æ¯”è¼ƒåœ–"""
        backbones = [r['backbone'] for r in all_results]
        overall_acc = [r['overall_accuracy'] for r in all_results]
        style_acc = [r['style_accuracy'] for r in all_results]
        gender_acc = [r['gender_accuracy'] for r in all_results]
        
        fig, ax = plt.subplots(figsize=(12, 8))
        
        x = np.arange(len(backbones))
        width = 0.25
        
        bars1 = ax.bar(x - width, overall_acc, width, label='Overall Accuracy', alpha=0.8)
        bars2 = ax.bar(x, style_acc, width, label='Style Accuracy', alpha=0.8)
        bars3 = ax.bar(x + width, gender_acc, width, label='Gender Accuracy', alpha=0.8)
        
        ax.set_xlabel('Backbone')
        ax.set_ylabel('Accuracy')
        ax.set_title('Classification Accuracy Comparison')
        ax.set_xticks(x)
        ax.set_xticklabels(backbones, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bars in [bars1, bars2, bars3]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        plot_path = os.path.join(self.output_dir, 'overall_accuracy_comparison.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.log_message(f"ğŸ“Š æ•´é«”æº–ç¢ºç‡æ¯”è¼ƒåœ–å·²ä¿å­˜: {plot_path}")
    
    def _plot_category_heatmap(self, all_results):
        """ç¹ªè£½å„é¡åˆ¥æº–ç¢ºç‡ç†±åŠ›åœ–"""
        # æº–å‚™æ•¸æ“š
        backbones = [r['backbone'] for r in all_results]
        
        # ç²å–æ‰€æœ‰é¡åˆ¥
        all_categories = set()
        for result in all_results:
            all_categories.update(result['category_results'].keys())
        all_categories = sorted(list(all_categories))
        
        # å‰µå»ºæº–ç¢ºç‡çŸ©é™£
        accuracy_matrix = []
        for result in all_results:
            row = []
            for category in all_categories:
                if category in result['category_results']:
                    cat_result = result['category_results'][category]
                    accuracy = cat_result['correct'] / cat_result['total'] if cat_result['total'] > 0 else 0
                else:
                    accuracy = 0
                row.append(accuracy)
            accuracy_matrix.append(row)
        
        # ç¹ªè£½ç†±åŠ›åœ–
        fig, ax = plt.subplots(figsize=(16, 10))
        
        im = ax.imshow(accuracy_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        
        # è¨­ç½®è»¸æ¨™ç±¤
        ax.set_xticks(np.arange(len(all_categories)))
        ax.set_yticks(np.arange(len(backbones)))
        ax.set_xticklabels(all_categories, rotation=45, ha='right')
        ax.set_yticklabels(backbones)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i in range(len(backbones)):
            for j in range(len(all_categories)):
                text = ax.text(j, i, f'{accuracy_matrix[i][j]:.3f}',
                              ha="center", va="center", color="black", fontsize=8)
        
        ax.set_title("Category-wise Accuracy Heatmap")
        fig.colorbar(im, ax=ax, label='Accuracy')
        
        plt.tight_layout()
        plot_path = os.path.join(self.output_dir, 'category_accuracy_heatmap.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.log_message(f"ğŸ“Š é¡åˆ¥æº–ç¢ºç‡ç†±åŠ›åœ–å·²ä¿å­˜: {plot_path}")
    
    def _plot_style_gender_scatter(self, all_results):
        """ç¹ªè£½é¢¨æ ¼vsæ€§åˆ¥æº–ç¢ºç‡æ•£ä½ˆåœ–"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        backbones = []
        style_accs = []
        gender_accs = []
        overall_accs = []
        
        for result in all_results:
            backbones.append(result['backbone'])
            style_accs.append(result['style_accuracy'])
            gender_accs.append(result['gender_accuracy'])
            overall_accs.append(result['overall_accuracy'])
        
        # ä½¿ç”¨æ•´é«”æº–ç¢ºç‡ä½œç‚ºé¡è‰²æ˜ å°„
        scatter = ax.scatter(style_accs, gender_accs, c=overall_accs, 
                           cmap='viridis', s=100, alpha=0.7)
        
        # æ·»åŠ æ¨™ç±¤
        for i, backbone in enumerate(backbones):
            ax.annotate(backbone, (style_accs[i], gender_accs[i]), 
                       xytext=(5, 5), textcoords='offset points', fontsize=9)
        
        ax.set_xlabel('Style Accuracy')
        ax.set_ylabel('Gender Accuracy')
        ax.set_title('Style vs Gender Accuracy')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ é¡è‰²æ¢
        cbar = fig.colorbar(scatter, ax=ax)
        cbar.set_label('Overall Accuracy')
        
        plt.tight_layout()
        plot_path = os.path.join(self.output_dir, 'style_gender_scatter.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.log_message(f"ğŸ“Š é¢¨æ ¼æ€§åˆ¥æ•£ä½ˆåœ–å·²ä¿å­˜: {plot_path}")
    
    def _plot_detailed_accuracy_bars(self, all_results):
        """ç¹ªè£½è©³ç´°æº–ç¢ºç‡æŸ±ç‹€åœ–"""
        # ç‚ºæ¯å€‹backboneå‰µå»ºå­åœ–
        n_backbones = len(all_results)
        fig, axes = plt.subplots(2, (n_backbones + 1) // 2, figsize=(20, 12))
        if n_backbones == 1:
            axes = [axes]
        elif n_backbones <= 2:
            axes = axes.flatten()
        else:
            axes = axes.flatten()
        
        for idx, result in enumerate(all_results):
            if idx >= len(axes):
                break
                
            ax = axes[idx]
            
            # æº–å‚™æ•¸æ“š
            categories = sorted(result['category_results'].keys())
            accuracies = []
            
            for category in categories:
                cat_result = result['category_results'][category]
                accuracy = cat_result['correct'] / cat_result['total'] if cat_result['total'] > 0 else 0
                accuracies.append(accuracy)
            
            # ç¹ªè£½æŸ±ç‹€åœ–
            bars = ax.bar(range(len(categories)), accuracies, alpha=0.7)
            
            # è¨­ç½®æ¨™ç±¤
            ax.set_title(f'{result["backbone"]} - Category Accuracy')
            ax.set_xlabel('Category')
            ax.set_ylabel('Accuracy')
            ax.set_xticks(range(len(categories)))
            ax.set_xticklabels(categories, rotation=45, ha='right', fontsize=8)
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, 1)
            
            # æ·»åŠ æ•¸å€¼æ¨™ç±¤
            for i, bar in enumerate(bars):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{height:.3f}', ha='center', va='bottom', fontsize=7)
            
            # æ·»åŠ å¹³å‡ç·š
            avg_accuracy = np.mean(accuracies)
            ax.axhline(y=avg_accuracy, color='red', linestyle='--', alpha=0.7,
                      label=f'Avg: {avg_accuracy:.3f}')
            ax.legend()
        
        # éš±è—å¤šé¤˜çš„å­åœ–
        for idx in range(len(all_results), len(axes)):
            axes[idx].set_visible(False)
        
        plt.tight_layout()
        plot_path = os.path.join(self.output_dir, 'detailed_category_accuracy.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.log_message(f"ğŸ“Š è©³ç´°é¡åˆ¥æº–ç¢ºç‡åœ–å·²ä¿å­˜: {plot_path}")
    
    def generate_summary_report(self, all_results):
        """ç”Ÿæˆç¸½çµå ±å‘Š"""
        self.log_message("ğŸ“‹ ç”Ÿæˆç¸½çµå ±å‘Š...")
        
        report_path = os.path.join(self.output_dir, 'summary_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("åˆ†é¡æº–ç¢ºç‡æ¸¬è©¦ç¸½çµå ±å‘Š\n")
            f.write("="*80 + "\n")
            f.write(f"æ¸¬è©¦æ™‚é–“: {datetime.now().isoformat()}\n")
            f.write(f"æ¸¬è©¦çš„Backboneæ•¸é‡: {len(all_results)}\n")
            f.write(f"æ¯å€‹æ¨¡å‹çš„æ¸¬è©¦åœ–ç‰‡æ•¸é‡: {all_results[0]['total_images'] if all_results else 0}\n")
            f.write("\n")
            
            # æ•´é«”æ’å
            f.write("ğŸ“Š æ•´é«”æº–ç¢ºç‡æ’å:\n")
            f.write("-" * 50 + "\n")
            sorted_results = sorted(all_results, key=lambda x: x['overall_accuracy'], reverse=True)
            for i, result in enumerate(sorted_results, 1):
                f.write(f"{i:2d}. {result['backbone']:15s} - {result['overall_accuracy']:.4f} "
                       f"({result['correct_predictions']}/{result['total_images']})\n")
            f.write("\n")
            
            # é¢¨æ ¼æº–ç¢ºç‡æ’å
            f.write("ğŸ¨ é¢¨æ ¼æº–ç¢ºç‡æ’å:\n")
            f.write("-" * 50 + "\n")
            sorted_by_style = sorted(all_results, key=lambda x: x['style_accuracy'], reverse=True)
            for i, result in enumerate(sorted_by_style, 1):
                f.write(f"{i:2d}. {result['backbone']:15s} - {result['style_accuracy']:.4f} "
                       f"({result['style_correct']}/{result['total_images']})\n")
            f.write("\n")
            
            # æ€§åˆ¥æº–ç¢ºç‡æ’å
            f.write("ğŸ‘¤ æ€§åˆ¥æº–ç¢ºç‡æ’å:\n")
            f.write("-" * 50 + "\n")
            sorted_by_gender = sorted(all_results, key=lambda x: x['gender_accuracy'], reverse=True)
            for i, result in enumerate(sorted_by_gender, 1):
                f.write(f"{i:2d}. {result['backbone']:15s} - {result['gender_accuracy']:.4f} "
                       f"({result['gender_correct']}/{result['total_images']})\n")
            f.write("\n")
            
            # è©³ç´°çµæœ
            f.write("ğŸ“‹ è©³ç´°çµæœ:\n")
            f.write("=" * 80 + "\n")
            for result in all_results:
                f.write(f"\nğŸ”§ {result['backbone']}:\n")
                f.write(f"  æ•´é«”æº–ç¢ºç‡: {result['overall_accuracy']:.4f}\n")
                f.write(f"  é¢¨æ ¼æº–ç¢ºç‡: {result['style_accuracy']:.4f}\n")
                f.write(f"  æ€§åˆ¥æº–ç¢ºç‡: {result['gender_accuracy']:.4f}\n")
                f.write(f"  æ­£ç¢ºé æ¸¬: {result['correct_predictions']}/{result['total_images']}\n")
                
                f.write("  å„é¡åˆ¥æº–ç¢ºç‡:\n")
                sorted_categories = sorted(result['category_results'].items())
                for category, cat_result in sorted_categories:
                    accuracy = cat_result['correct'] / cat_result['total'] if cat_result['total'] > 0 else 0
                    f.write(f"    {category:20s}: {accuracy:.4f} ({cat_result['correct']}/{cat_result['total']})\n")
                f.write("\n")
        
        self.log_message(f"ğŸ“‹ ç¸½çµå ±å‘Šå·²ä¿å­˜: {report_path}")
        return report_path

# ==================== ä¸»ç¨‹åº ====================

def main():
    parser = argparse.ArgumentParser(description='æ™‚å°šAIåˆ†é¡æº–ç¢ºç‡æ¸¬è©¦ç³»çµ±')
    parser.add_argument('--test_data', type=str, required=True,
                       help='æ¸¬è©¦æ•¸æ“šç›®éŒ„è·¯å¾‘')
    parser.add_argument('--models_dir', type=str, required=True,
                       help='æ¨¡å‹ç›®éŒ„è·¯å¾‘')
    parser.add_argument('--output_dir', type=str, default='test_results',
                       help='çµæœè¼¸å‡ºç›®éŒ„')
    parser.add_argument('--platform', type=str, default='auto',
                       choices=['auto', 'cuda', 'mps', 'cpu'],
                       help='è¨ˆç®—å¹³å°')
    parser.add_argument('--models', type=str, nargs='+',
                       help='æŒ‡å®šè¦æ¸¬è©¦çš„æ¨¡å‹æ–‡ä»¶ï¼ˆä¸æŒ‡å®šå‰‡æ¸¬è©¦æ‰€æœ‰.pthæ–‡ä»¶ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸ¤– æ™‚å°šAIåˆ†é¡æº–ç¢ºç‡æ¸¬è©¦ç³»çµ±")
    print("=" * 80)
    
    # æª¢æŸ¥ç›®éŒ„
    if not os.path.exists(args.test_data):
        print(f"âŒ æ¸¬è©¦æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {args.test_data}")
        return
    
    if not os.path.exists(args.models_dir):
        print(f"âŒ æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: {args.models_dir}")
        return
    
    # è¨­ç½®è¨­å‚™
    device = setup_device(args.platform)
    
    # åˆå§‹åŒ–çµ„ä»¶
    test_data_loader = TestDataLoader(args.test_data)
    model_tester = ModelTester(device)
    result_analyzer = ResultAnalyzer(args.output_dir)
    
    # ç²å–è¦æ¸¬è©¦çš„æ¨¡å‹åˆ—è¡¨
    if args.models:
        model_files = args.models
    else:
        # è‡ªå‹•æƒææ¨¡å‹ç›®éŒ„
        model_files = [f for f in os.listdir(args.models_dir) if f.endswith('.pth')]
        model_files.sort()
    
    if not model_files:
        print("âŒ æ²’æœ‰æ‰¾åˆ°è¦æ¸¬è©¦çš„æ¨¡å‹æ–‡ä»¶")
        return
    
    result_analyzer.log_message(f"ğŸ” æ‰¾åˆ° {len(model_files)} å€‹æ¨¡å‹æ–‡ä»¶:")
    for model_file in model_files:
        result_analyzer.log_message(f"  - {model_file}")
    
    # æ¸¬è©¦æ‰€æœ‰æ¨¡å‹
    all_results = []
    
    for model_file in model_files:
        try:
            result_analyzer.log_message(f"\nğŸ§ª é–‹å§‹æ¸¬è©¦æ¨¡å‹: {model_file}")
            
            # å¾æª”åè§£æbackboneé¡å‹
            backbone_type = extract_backbone_from_filename(model_file)
            result_analyzer.log_message(f"ğŸ”§ æª¢æ¸¬åˆ°backboneé¡å‹: {backbone_type}")
            
            # è¼‰å…¥æ¨¡å‹
            model_path = os.path.join(args.models_dir, model_file)
            model = model_tester.load_model(model_path, backbone_type)
            
            # æ¸¬è©¦æ¨¡å‹
            result = model_tester.test_model(model, test_data_loader, backbone_type)
            all_results.append(result)
            
            # è¨˜éŒ„çµæœ
            result_analyzer.log_message(f"âœ… {backbone_type} æ¸¬è©¦å®Œæˆ:")
            result_analyzer.log_message(f"   æ•´é«”æº–ç¢ºç‡: {result['overall_accuracy']:.4f}")
            result_analyzer.log_message(f"   é¢¨æ ¼æº–ç¢ºç‡: {result['style_accuracy']:.4f}")
            result_analyzer.log_message(f"   æ€§åˆ¥æº–ç¢ºç‡: {result['gender_accuracy']:.4f}")
            
            # é‡‹æ”¾è¨˜æ†¶é«”
            del model
            if device.type == 'cuda':
                torch.cuda.empty_cache()
            elif device.type == 'mps':
                torch.mps.empty_cache()
            
        except Exception as e:
            result_analyzer.log_message(f"âŒ æ¸¬è©¦æ¨¡å‹ {model_file} å¤±æ•—: {e}")
            continue
    
    if not all_results:
        print("âŒ æ²’æœ‰æˆåŠŸæ¸¬è©¦ä»»ä½•æ¨¡å‹")
        return
    
    # ä¿å­˜çµæœ
    result_analyzer.log_message(f"\nğŸ“Š æ¸¬è©¦å®Œæˆï¼Œå…±æ¸¬è©¦äº† {len(all_results)} å€‹æ¨¡å‹")
    
    # ä¿å­˜CSVçµæœ
    csv_file = result_analyzer.save_results_to_csv(all_results)
    
    # å‰µå»ºè¦–è¦ºåŒ–
    result_analyzer.create_visualizations(all_results)
    
    # ç”Ÿæˆç¸½çµå ±å‘Š
    summary_report = result_analyzer.generate_summary_report(all_results)
    
    # é¡¯ç¤ºæœ€çµ‚çµæœ
    print(f"\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
    print(f"ğŸ“ çµæœç›®éŒ„: {args.output_dir}")
    print(f"ğŸ“Š CSVçµæœ: {csv_file}")
    print(f"ğŸ“‹ ç¸½çµå ±å‘Š: {summary_report}")
    print(f"ğŸ“ˆ è¦–è¦ºåŒ–åœ–è¡¨å·²ä¿å­˜åˆ°çµæœç›®éŒ„")
    
    # é¡¯ç¤ºæ’å
    print(f"\nğŸ† æ•´é«”æº–ç¢ºç‡æ’å:")
    sorted_results = sorted(all_results, key=lambda x: x['overall_accuracy'], reverse=True)
    for i, result in enumerate(sorted_results, 1):
        print(f"  {i}. {result['backbone']:15s} - {result['overall_accuracy']:.4f}")

def extract_backbone_from_filename(filename):
    """å¾æª”åæå–backboneé¡å‹"""
    filename_lower = filename.lower()
    
    # å®šç¾©backboneé¡å‹åŒ¹é…è¦å‰‡
    backbone_patterns = {
        'mobilenet': ['mobilenet'],
        'resnet18': ['resnet18'],
        'resnet50': ['resnet50'],
        'efficientnet_b0': ['efficientnet_b0', 'efficientnetb0'],
        'efficientnet_b2': ['efficientnet_b2', 'efficientnetb2'],
        'vit_tiny': ['vit_tiny', 'vittiny'],
        'vit_small': ['vit_small', 'vitsmall'],
        'fashion_resnet': ['fashion_resnet', 'fashionresnet']
    }
    
    for backbone_type, patterns in backbone_patterns.items():
        for pattern in patterns:
            if pattern in filename_lower:
                return backbone_type
    
    # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°ï¼Œå˜—è©¦æ›´å¯¬é¬†çš„åŒ¹é…
    if 'resnet' in filename_lower:
        if '18' in filename_lower:
            return 'resnet18'
        elif '50' in filename_lower:
            return 'resnet50'
        else:
            return 'resnet18'  # é»˜èª
    elif 'efficient' in filename_lower:
        if 'b2' in filename_lower:
            return 'efficientnet_b2'
        else:
            return 'efficientnet_b0'  # é»˜èª
    elif 'vit' in filename_lower:
        if 'small' in filename_lower:
            return 'vit_small'
        else:
            return 'vit_tiny'  # é»˜èª
    elif 'mobile' in filename_lower:
        return 'mobilenet'
    
    # å¦‚æœéƒ½æ²’æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜èªå€¼
    print(f"âš ï¸ ç„¡æ³•å¾æª”å {filename} è­˜åˆ¥backboneé¡å‹ï¼Œä½¿ç”¨é»˜èªå€¼ mobilenet")
    return 'mobilenet'

if __name__ == "__main__":
    main()