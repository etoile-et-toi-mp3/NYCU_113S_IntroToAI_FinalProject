#!/usr/bin/env python3
"""
Mac å„ªåŒ–çš„æœè£é¢¨æ ¼åˆ†é¡è¨“ç·´è…³æœ¬
ä½¿ç”¨æ–¹æ³•:
    python run_mac_training.py --config balanced
    python run_mac_training.py --config minimal
    python run_mac_training.py --config performance
"""

import argparse
import sys
import os
from mac_train_config import MacTrainingConfig, QuickConfigs



def check_dataset(data_root):
    """æª¢æŸ¥æ•¸æ“šé›†æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(data_root):
        print(f"âŒ æ•¸æ“šé›†ç›®éŒ„ä¸å­˜åœ¨: {data_root}")
        print("è«‹ç¢ºä¿æ•¸æ“šé›†ç›®éŒ„å­˜åœ¨ä¸¦åŒ…å«æ­£ç¢ºçš„å­ç›®éŒ„çµæ§‹")
        return False
    
    # æª¢æŸ¥æ˜¯å¦æœ‰é¢¨æ ¼ç›®éŒ„
    style_categories = [
        'Athleisure', 'BRITISH', 'CASUAL', 'GOTH', 'Kawaii', 
        'Korean', 'MINIMALIST', 'Preppy', 'STREET', 'Streetwear', 
        'Vintage', 'Y2K'
    ]
    gender_categories = ['MEN', 'WOMEN']
    
    found_dirs = 0
    for style in style_categories:
        for gender in gender_categories:
            folder_name = f"{style}_{gender}"
            folder_path = os.path.join(data_root, folder_name)
            if os.path.exists(folder_path):
                found_dirs += 1
    
    if found_dirs == 0:
        print(f"âŒ åœ¨ {data_root} ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½•é¢¨æ ¼ç›®éŒ„")
        print("é æœŸçš„ç›®éŒ„æ ¼å¼: Style_Gender (ä¾‹å¦‚: CASUAL_MEN, Kawaii_WOMEN)")
        return False
    
    print(f"âœ… æ‰¾åˆ° {found_dirs} å€‹é¢¨æ ¼ç›®éŒ„")
    return True

def main():
    parser = argparse.ArgumentParser(description='Mac å„ªåŒ–çš„æœè£é¢¨æ ¼åˆ†é¡è¨“ç·´')
    parser.add_argument('--config', type=str, default='balanced',
                       choices=['minimal', 'balanced', 'performance'],
                       help='é¸æ“‡é…ç½®é è¨­ (default: balanced)')
    parser.add_argument('--data-root', type=str, default='./dataset',
                       help='æ•¸æ“šé›†æ ¹ç›®éŒ„ (default: ./dataset)')
    parser.add_argument('--resume', type=str, default=None,
                       help='å¾æª¢æŸ¥é»æ¢å¾©è¨“ç·´çš„è·¯å¾‘')
    parser.add_argument('--dry-run', action='store_true',
                       help='åªæª¢æŸ¥é…ç½®ï¼Œä¸å¯¦éš›è¨“ç·´')
    
    args = parser.parse_args()
    
    print("ğŸ Mac æœè£é¢¨æ ¼åˆ†é¡è¨“ç·´å™¨")
    print("=" * 50)
    
    
    # æª¢æŸ¥æ•¸æ“šé›†
    if not check_dataset(args.data_root):
        sys.exit(1)
    
    # é¸æ“‡é…ç½®
    if args.config == 'minimal':
        config = QuickConfigs.minimal()
        print("ğŸ“± ä½¿ç”¨æœ€å°é…ç½® (é©åˆä½è¨˜æ†¶é«”è¨­å‚™)")
    elif args.config == 'performance':
        config = QuickConfigs.performance()
        print("ğŸš€ ä½¿ç”¨æ€§èƒ½é…ç½® (é©åˆé«˜ç«¯è¨­å‚™)")
    else:
        config = QuickConfigs.balanced()
        print("âš–ï¸  ä½¿ç”¨å¹³è¡¡é…ç½® (æ¨è–¦)")
    
    # æ ¹æ“šè¨­å‚™è‡ªå‹•èª¿æ•´
    config = config.get_device_specific_config()
    config.DATA_ROOT = args.data_root
    config.print_config()
    
    if args.dry_run:
        print("ğŸ” ä¹¾é‹è¡Œæ¨¡å¼ - é…ç½®æª¢æŸ¥å®Œæˆ")
        return
    
    # å°å…¥è¨“ç·´æ¨¡çµ„
    try:
        from test_mac_optimized import (
            setup_mac_optimization, OptimizedOutfitDataset, 
            LightweightStyleClassifier, MacOptimizedTrainer
        )
        import torch
        import torch.nn as nn
        from torch.utils.data import DataLoader
        import torchvision.transforms as transforms
        import gc
    except ImportError as e:
        print(f"âŒ å°å…¥è¨“ç·´æ¨¡çµ„å¤±æ•—: {e}")
        sys.exit(1)
    
    # é–‹å§‹è¨“ç·´
    print("\nğŸš€ é–‹å§‹è¨“ç·´...")
    
    # è¨­å‚™è¨­ç½®
    device = setup_mac_optimization()
    
    # æ•¸æ“šå¢å¼·
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=config.HORIZONTAL_FLIP_PROB),
        transforms.ColorJitter(
            brightness=config.COLOR_JITTER_BRIGHTNESS,
            contrast=config.COLOR_JITTER_CONTRAST
        ),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # å»ºç«‹æ•¸æ“šé›†
    train_dataset = OptimizedOutfitDataset(
        config.DATA_ROOT,
        transform=train_transform,
        max_samples_per_class=config.MAX_SAMPLES_PER_CLASS
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=True,
        num_workers=config.NUM_WORKERS,
        pin_memory=config.PIN_MEMORY,
        drop_last=config.DROP_LAST,
        persistent_workers=config.PERSISTENT_WORKERS
    )
    
    # å»ºç«‹æ¨¡å‹
    model = LightweightStyleClassifier(
        num_styles=config.NUM_STYLES,
        num_genders=config.NUM_GENDERS,
        feature_dim=config.FEATURE_DIM
    )
    model.to(device)
    
    # è¨ˆç®—åƒæ•¸æ•¸é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“ˆ æ¨¡å‹åƒæ•¸: {total_params:,} (å¯è¨“ç·´: {trainable_params:,})")
    
    # è¨“ç·´å™¨
    trainer = MacOptimizedTrainer(model, device)
    
    # å„ªåŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.LEARNING_RATE,
        weight_decay=config.WEIGHT_DECAY,
        betas=config.OPTIMIZER_BETAS
    )
    
    # å­¸ç¿’ç‡èª¿åº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.NUM_EPOCHS,
        eta_min=config.LEARNING_RATE * config.SCHEDULER_ETA_MIN_RATIO
    )
    
    # æ¢å¾©è¨“ç·´
    start_epoch = 0
    best_loss = float('inf')
    
    if args.resume and os.path.exists(args.resume):
        print(f"ğŸ”„ å¾æª¢æŸ¥é»æ¢å¾©: {args.resume}")
        checkpoint = torch.load(args.resume, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_loss = checkpoint.get('loss', float('inf'))
    
    # è¨“ç·´å¾ªç’°
    try:
        for epoch in range(start_epoch, config.NUM_EPOCHS):
            print(f"\n{'='*50}")
            print(f"ğŸ“… Epoch {epoch+1}/{config.NUM_EPOCHS}")
            print(f"{'='*50}")
            
            # è¨“ç·´ä¸€å€‹epoch
            avg_loss = trainer.train_epoch(
                train_loader, optimizer, epoch, config.MAX_MEMORY_MB
            )
            scheduler.step()
            
            current_lr = optimizer.param_groups[0]['lr']
            memory_usage = trainer.get_memory_usage()
            
            print(f"ğŸ“Š Epoch {epoch+1} çµæœ:")
            print(f"  å¹³å‡æå¤±: {avg_loss:.4f}")
            print(f"  å­¸ç¿’ç‡: {current_lr:.6f}")
            print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {memory_usage:.1f}MB")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_loss < best_loss and avg_loss > 0:
                best_loss = avg_loss
                torch.save(model.state_dict(), config.BEST_MODEL_PATH)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œæå¤±: {best_loss:.4f}")
            
            # ä¿å­˜æª¢æŸ¥é»
            if (epoch + 1) % config.SAVE_CHECKPOINT_EVERY == 0:
                # å‰µå»ºå¯åºåˆ—åŒ–çš„é…ç½®å­—å…¸
                config_dict = {}
                for key, value in config.__dict__.items():
                    if isinstance(value, (int, float, str, bool, list, tuple)):
                        config_dict[key] = value
                
                checkpoint = {
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'loss': avg_loss,
                    'config': config_dict
                }
                checkpoint_path = f"{config.CHECKPOINT_PREFIX}{epoch+1}.pth"
                torch.save(checkpoint, checkpoint_path)
                print(f"ğŸ’¾ ä¿å­˜æª¢æŸ¥é»: {checkpoint_path}")
            
            # è¨˜æ†¶é«”æ¸…ç†
            gc.collect()
            if device.type == 'mps':
                torch.mps.empty_cache()
    
    except KeyboardInterrupt:
        print("\nâš ï¸  è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·")
        # ä¿å­˜ç•¶å‰ç‹€æ…‹
        config_dict = {}
        for key, value in config.__dict__.items():
            if isinstance(value, (int, float, str, bool, list, tuple)):
                config_dict[key] = value
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'loss': avg_loss if 'avg_loss' in locals() else float('inf'),
            'config': config_dict
        }
        torch.save(checkpoint, 'interrupted_checkpoint.pth')
        print("ğŸ’¾ å·²ä¿å­˜ä¸­æ–·æª¢æŸ¥é»: interrupted_checkpoint.pth")
    
    except Exception as e:
        print(f"âŒ è¨“ç·´éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)
    
    # ä¿å­˜æœ€çµ‚æ¨¡å‹
    torch.save(model.state_dict(), config.FINAL_MODEL_PATH)
    
    print("\nğŸ‰ è¨“ç·´å®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - {config.BEST_MODEL_PATH} (æœ€ä½³æ¨¡å‹)")
    print(f"  - {config.FINAL_MODEL_PATH} (æœ€çµ‚æ¨¡å‹)")
    print("  - checkpoint_mac_epoch_*.pth (æª¢æŸ¥é»)")

if __name__ == "__main__":
    main() 