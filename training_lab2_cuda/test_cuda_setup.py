#!/usr/bin/env python3
"""
Cuda è¨­ç½®æ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰ Cuda è¨“ç·´ç’°å¢ƒæ˜¯å¦æ­£ç¢ºé…ç½®
"""

import sys
import torch
import platform

def test_python_version():
    """æ¸¬è©¦ Python ç‰ˆæœ¬"""
    print("ğŸ Python ç‰ˆæœ¬æª¢æŸ¥...")
    version = sys.version_info
    print(f"   ç•¶å‰ç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    
    if version.major >= 3 and version.minor >= 8:
        print("   âœ… Python ç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (3.8+)")
        return True
    else:
        print("   âŒ Python ç‰ˆæœ¬éä½ï¼Œå»ºè­°ä½¿ç”¨ 3.8+")
        return False

def test_system_info():
    """æ¸¬è©¦ç³»çµ±è³‡è¨Šèˆ‡ CUDA æ”¯æ´æƒ…æ³"""
    print("\nğŸ’» ç³»çµ±è³‡è¨Š...")
    print(f"   ä½œæ¥­ç³»çµ±: {platform.system()}")
    print(f"   ç‰ˆæœ¬: {platform.release()}")
    print(f"   æ¶æ§‹: {platform.machine()}")

    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        cuda_version = torch.version.cuda
        device_count = torch.cuda.device_count()
        print(f"   âœ… æª¢æ¸¬åˆ° CUDA æ”¯æ´: {device_name}")
        print(f"   âœ… CUDA ç‰ˆæœ¬: {cuda_version}")
        print(f"   âœ… å¯ç”¨ GPU æ•¸é‡: {device_count}")
        return True
    else:
        print("   âš ï¸ æœªæª¢æ¸¬åˆ° CUDA, å°‡ä½¿ç”¨ CPU åŸ·è¡Œ")
        return False


def test_memory():
    """æ¸¬è©¦è¨˜æ†¶é«”"""
    print("\nğŸ§  è¨˜æ†¶é«”æª¢æŸ¥...")
    try:
        import psutil
        memory = psutil.virtual_memory()
        total_gb = memory.total / (1024**3)
        available_gb = memory.available / (1024**3)
        
        print(f"   ç¸½è¨˜æ†¶é«”: {total_gb:.1f} GB")
        print(f"   å¯ç”¨è¨˜æ†¶é«”: {available_gb:.1f} GB")
        
        if total_gb >= 8:
            print("   âœ… è¨˜æ†¶é«”å……è¶³")
            return True
        elif total_gb >= 4:
            print("   âš ï¸ è¨˜æ†¶é«”è¼ƒå°‘ï¼Œå»ºè­°ä½¿ç”¨æœ€å°é…ç½®")
            return True
        else:
            print("   âŒ è¨˜æ†¶é«”ä¸è¶³ï¼Œå¯èƒ½å½±éŸ¿è¨“ç·´")
            return False
    except ImportError:
        print("   âŒ ç„¡æ³•æª¢æŸ¥è¨˜æ†¶é«” (ç¼ºå°‘ psutil)")
        return False

def test_vram():
    """æ¸¬è©¦ CUDA VRAM"""
    print("\nğŸ§  VRAM æª¢æŸ¥...")
    try:
        import torch
        if not torch.cuda.is_available():
            print("   âŒ æœªåµæ¸¬åˆ°å¯ç”¨çš„ CUDA GPU")
            return False

        device = torch.cuda.get_device_properties(0)
        total_vram_gb = device.total_memory / (1024 ** 3)
        device_name = device.name

        print(f"   GPU è£ç½®: {device_name}")
        print(f"   ç¸½ VRAM: {total_vram_gb:.1f} GB")

        if total_vram_gb >= 16:
            print("   âœ… VRAM å……è¶³ï¼Œé©ç”¨é«˜æ•ˆèƒ½é…ç½®")
            return True
        elif total_vram_gb >= 6:
            print("   âš ï¸ VRAM ä¸€èˆ¬ï¼Œå»ºè­°ä½¿ç”¨å¹³è¡¡é…ç½®")
            return True
        else:
            print("   âš ï¸ VRAM åä½ï¼Œå»ºè­°ä½¿ç”¨æœ€å°é…ç½®")
            return True
    except Exception as e:
        print(f"   âŒ ç„¡æ³•æª¢æŸ¥ VRAM: {e}")
        return False

def test_pytorch():
    """æ¸¬è©¦ PyTorch èˆ‡ CUDA"""
    print("\nğŸ”¥ PyTorch æª¢æŸ¥...")
    try:
        import torch
        print(f"   PyTorch ç‰ˆæœ¬: {torch.__version__}")
        
        # æª¢æŸ¥ CUDA æ”¯æ´
        if torch.cuda.is_available():
            device = torch.device("cuda")
            device_name = torch.cuda.get_device_name(0)
            print(f"   âœ… CUDA å¯ç”¨: {device_name}")
            
            # æ¸¬è©¦ CUDA è¨­å‚™å¼µé‡æ“ä½œ
            try:
                test_tensor = torch.randn(10, 10, device=device)
                result = torch.matmul(test_tensor, test_tensor.T)
                print("   âœ… CUDA è¨­å‚™æ¸¬è©¦æˆåŠŸ")
                return True
            except Exception as e:
                print(f"   âŒ CUDA è¨­å‚™æ¸¬è©¦å¤±æ•—: {e}")
                return False
        else:
            print("   âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨ CPU åŸ·è¡Œ")
            return True  # PyTorch still usable on CPU

    except ImportError:
        print("   âŒ PyTorch æœªå®‰è£")
        return False


def test_dependencies():
    """æ¸¬è©¦ä¾è³´å¥—ä»¶"""
    print("\nğŸ“¦ ä¾è³´å¥—ä»¶æª¢æŸ¥...")
    
    required_packages = {
        'torch': 'PyTorch',
        'torchvision': 'TorchVision',
        'PIL': 'Pillow',
        'cv2': 'OpenCV',
        'numpy': 'NumPy',
        'sklearn': 'Scikit-learn',
        'psutil': 'PSUtil',
        'matplotlib': 'Matplotlib'
    }
    
    missing_packages = []
    
    for package, name in required_packages.items():
        try:
            __import__(package)
            print(f"   âœ… {name}")
        except ImportError:
            print(f"   âŒ {name} (ç¼ºå°‘)")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\n   ç¼ºå°‘çš„å¥—ä»¶: {', '.join(missing_packages)}")
        print("   å®‰è£å‘½ä»¤:")
        
        # ç‰¹æ®Šè™•ç†ä¸€äº›å¥—ä»¶åç¨±
        install_names = []
        for pkg in missing_packages:
            if pkg == 'cv2':
                install_names.append('opencv-python')
            elif pkg == 'PIL':
                install_names.append('pillow')
            elif pkg == 'sklearn':
                install_names.append('scikit-learn')
            else:
                install_names.append(pkg)
        
        print(f"   pip install {' '.join(install_names)}")
        return False
    
    return True

def test_model_creation():
    """æ¸¬è©¦æ¨¡å‹å‰µå»ºèˆ‡ CUDA è¨­å‚™è½‰ç§»"""
    print("\nğŸ¤– æ¨¡å‹å‰µå»ºæ¸¬è©¦...")
    try:
        import torch
        import torch.nn as nn
        import torchvision.models as models

        # å˜—è©¦å‰µå»º MobileNetV3 æ¨¡å‹
        try:
            model = models.mobilenet_v3_large(weights=None)
            print("   âœ… MobileNetV3 å¯ç”¨")
        except:
            # è‹¥å¤±æ•—å‰‡å˜—è©¦ ResNet18
            try:
                model = models.resnet18(weights=None)
                print("   âœ… ResNet18 å¯ç”¨")
            except Exception as e:
                print(f"   âŒ æ¨¡å‹å‰µå»ºå¤±æ•—: {e}")
                return False

        # é¸æ“‡è¨­å‚™ï¼šCUDA > CPU
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"   âœ… CUDA å¯ç”¨: {torch.cuda.get_device_name(0)}")
        else:
            device = torch.device("cpu")
            print("   âš ï¸ CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")

        # å°‡æ¨¡å‹è½‰ç§»åˆ°è¨­å‚™
        model.to(device)
        print(f"   âœ… æ¨¡å‹æˆåŠŸè½‰ç§»åˆ° {device}")

        # åŸ·è¡Œä¸€æ¬¡å‰å‘å‚³æ’­ä»¥æ¸¬è©¦å®Œæ•´æµç¨‹
        model.eval()
        dummy_input = torch.randn(1, 3, 224, 224, device=device)
        with torch.no_grad():
            output = model(dummy_input)
        print("   âœ… æ¨¡å‹å‰å‘å‚³æ’­æ¸¬è©¦æˆåŠŸ")

        return True

    except Exception as e:
        print(f"   âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_data_loading():
    """æ¸¬è©¦æ•¸æ“šè¼‰å…¥"""
    print("\nğŸ“ æ•¸æ“šè¼‰å…¥æ¸¬è©¦...")
    try:
        from torch.utils.data import Dataset, DataLoader
        import torchvision.transforms as transforms
        from PIL import Image
        import numpy as np
        
        # å‰µå»ºè™›æ“¬æ•¸æ“šé›†
        class DummyDataset(Dataset):
            def __init__(self, size=10):
                self.size = size
                self.transform = transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                       std=[0.229, 0.224, 0.225])
                ])
            
            def __len__(self):
                return self.size
            
            def __getitem__(self, idx):
                # å‰µå»ºè™›æ“¬åœ–ç‰‡
                image = Image.fromarray(np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8))
                image = self.transform(image)
                return {'image': image, 'label': idx % 2}
        
        dataset = DummyDataset()
        dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)
        
        # æ¸¬è©¦ä¸€å€‹æ‰¹æ¬¡
        for batch in dataloader:
            images = batch['image']
            labels = batch['label']
            print(f"   âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œæ‰¹æ¬¡å½¢ç‹€: {images.shape}")
            break
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ•¸æ“šè¼‰å…¥æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸŸ© Cuda è¨“ç·´ç’°å¢ƒæª¢æŸ¥")
    print("=" * 50)
    
    tests = [
        ("Python ç‰ˆæœ¬", test_python_version),
        ("ç³»çµ±è³‡è¨Š", test_system_info),
        ("è¨˜æ†¶é«”", test_memory),
        ("é¡¯å­˜", test_vram),
        ("PyTorch", test_pytorch),
        ("ä¾è³´å¥—ä»¶", test_dependencies),
        ("æ¨¡å‹å‰µå»º", test_model_creation),
        ("æ•¸æ“šè¼‰å…¥", test_data_loading)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"   âŒ æ¸¬è©¦ {test_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            results.append((test_name, False))
    
    # ç¸½çµ
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\né€šéç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ‚¨çš„ç³»çµ±å·²æº–å‚™å¥½é€²è¡Œè¨“ç·´ã€‚")
        print("\nå»ºè­°çš„ä¸‹ä¸€æ­¥:")
        print("1. æº–å‚™æ‚¨çš„æ•¸æ“šé›†")
        print("2. é‹è¡Œ: python3 run_cuda_training.py --config balanced --dry-run")
        print("3. é–‹å§‹è¨“ç·´: python3 run_cuda_training.py --config balanced")
    elif passed >= total * 0.7:
        print("\nâš ï¸ å¤§éƒ¨åˆ†æ¸¬è©¦é€šéï¼Œä½†æœ‰ä¸€äº›å•é¡Œéœ€è¦è§£æ±ºã€‚")
        print("è«‹æŸ¥çœ‹ä¸Šé¢çš„éŒ¯èª¤è¨Šæ¯ä¸¦ä¿®å¾©å•é¡Œã€‚")
    else:
        print("\nâŒ å¤šå€‹æ¸¬è©¦å¤±æ•—ï¼Œè«‹å…ˆè§£æ±ºä¾è³´å’Œé…ç½®å•é¡Œã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 