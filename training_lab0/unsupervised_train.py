#!/usr/bin/env python3
"""
æ™‚å°šAIç„¡ç›£ç£å­¸ç¿’è¨“ç·´ç³»çµ±
æ”¯æ´å¤šç¨®backboneæ¶æ§‹çš„SimCLRå°æ¯”å­¸ç¿’è¨“ç·´
"""

# è¨­ç½®matplotlibä¸å½ˆå‡ºè¦–çª—
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import torchvision.models as models
import timm
from transformers import ViTModel, ViTConfig
import numpy as np
from PIL import Image
import os
import matplotlib.pyplot as plt
import json
import time
import gc
import psutil
import multiprocessing as mp
import argparse
from datetime import datetime
from pathlib import Path
import warnings
import pillow_avif

# ==================== Macå„ªåŒ–è¨­ç½® ====================

def setup_mac_optimization():
    """è¨­ç½®Macç‰¹å®šçš„å„ªåŒ–"""
    if mp.get_start_method(allow_none=True) != 'spawn':
        mp.set_start_method('spawn', force=True)
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("âœ… æª¢æ¸¬åˆ° Metal Performance Shaders (MPS) æ”¯æŒ")
        device = torch.device("mps")
    else:
        print("âš ï¸  MPS ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
        device = torch.device("cpu")
    
    torch.set_num_threads(min(8, mp.cpu_count()))
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    
    return device

# ==================== CudaåŠ é€Ÿè¨­ç½® ====================

def setup_cuda_optimization():
    """è¨­ç½® NVIDIA CUDA ç‰¹å®šçš„å„ªåŒ–"""
    if mp.get_start_method(allow_none=True) != 'spawn':
        mp.set_start_method('spawn', force=True)

    if torch.cuda.is_available():
        print(f"âœ… æª¢æ¸¬åˆ° CUDA æ”¯æŒ: {torch.cuda.get_device_name(0)}")
        device = torch.device("cuda")
        
        # CUDA æ€§èƒ½å„ªåŒ–é¸é …
        torch.backends.cudnn.benchmark = True  # é©ç”¨æ–¼è¼¸å…¥å°ºå¯¸å›ºå®šçš„æ¨¡å‹
        torch.backends.cudnn.deterministic = False  # æé«˜é€Ÿåº¦ä½†çµæœéå®Œå…¨å¯é‡ç¾
    else:
        print("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
        device = torch.device("cpu")

    # æ ¹æ“š CPU æ ¸å¿ƒæ•¸è¨­ç½® PyTorch ç·šç¨‹æ•¸
    torch.set_num_threads(min(8, mp.cpu_count()))

    return device


# ==================== è¼¸å‡ºç®¡ç† ====================

def create_output_directory(base_dir="unsupervised_result"):
    """å‰µå»ºè¼¸å‡ºç›®éŒ„ï¼Œæ ¼å¼ç‚º unsupervised_result/[yyyymmddhhmmss]/"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    output_dir = os.path.join(base_dir, timestamp)
    os.makedirs(output_dir, exist_ok=True)
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    return output_dir

def save_config_to_file(config, output_dir):
    """ä¿å­˜è¨“ç·´é…ç½®åˆ°æ–‡ä»¶"""
    config_dict = {
        'config_type': config.config_type,
        'backbone_type': config.backbone_type,
        'feature_dim': config.feature_dim,
        'batch_size': config.batch_size,
        'num_epochs': config.num_epochs,
        'learning_rate': config.learning_rate,
        'max_samples_per_class': config.max_samples_per_class,
        'num_workers': config.num_workers,
        'max_memory_mb': config.max_memory_mb,
        'temperature': config.temperature,
        'timestamp': datetime.now().isoformat()
    }
    
    config_path = os.path.join(output_dir, 'training_config.json')
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ è¨“ç·´é…ç½®å·²ä¿å­˜: {config_path}")

def save_training_history_plot(train_history, output_dir):
    """ä¿å­˜è¨“ç·´æ­·å²åœ–è¡¨"""
    if not train_history['epoch']:
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Unsupervised Training History', fontsize=16)
    
    # æå¤±åœ–
    axes[0, 0].plot(train_history['epoch'], train_history['loss'], 'b-', label='Contrastive Loss')
    axes[0, 0].set_title('Training Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # å­¸ç¿’ç‡åœ–
    axes[0, 1].plot(train_history['epoch'], train_history['lr'], 'm-', label='Learning Rate')
    axes[0, 1].set_title('Learning Rate')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Learning Rate')
    axes[0, 1].legend()
    axes[0, 1].grid(True)
    
    # è¨˜æ†¶é«”ä½¿ç”¨åœ–
    axes[1, 0].plot(train_history['epoch'], train_history['memory_usage'], 'c-', label='Memory Usage')
    axes[1, 0].set_title('Memory Usage')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Memory (MB)')
    axes[1, 0].legend()
    axes[1, 0].grid(True)
    
    # æº«åº¦åƒæ•¸åœ–
    axes[1, 1].plot(train_history['epoch'], [train_history['temperature'][0]] * len(train_history['epoch']), 'r-', label=f'Temperature ({train_history["temperature"][0]})')
    axes[1, 1].set_title('Temperature Parameter')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Temperature')
    axes[1, 1].legend()
    axes[1, 1].grid(True)
    
    plt.tight_layout()
    
    plot_path = os.path.join(output_dir, 'training_history.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“Š è¨“ç·´æ­·å²åœ–è¡¨å·²ä¿å­˜: {plot_path}")

# ==================== é…ç½®ç®¡ç† ====================

class TrainingConfig:
    """è¨“ç·´é…ç½®é¡"""
    def __init__(self, config_type="balanced", backbone_type="resnet50", device="cpu"):
        self.config_type = config_type
        self.backbone_type = backbone_type
        
        # åŸºç¤é…ç½®
        self.feature_dim = 128
        self.temperature = 0.2
        self.max_samples_per_class = None  # ç„¡ç›£ç£ä¸éœ€è¦é¡åˆ¥é™åˆ¶
        
        # æ ¹æ“šé…ç½®é¡å‹è¨­ç½®åƒæ•¸
        if device == "cuda":
            if config_type == "minimal":
                self._cuda_set_minimal_config()
            elif config_type == "performance":
                self._cuda_set_performance_config()
            else:  # balanced
                self._cuda_set_balanced_config()
        else:
            if config_type == "minimal":
                self._mac_set_minimal_config()
            elif config_type == "performance":
                self._mac_set_performance_config()
            else:  # balanced
                self._mac_set_balanced_config()
    
    def _mac_set_minimal_config(self):
        """æœ€å°é…ç½® - é©åˆè¨˜æ†¶é«”æœ‰é™çš„æƒ…æ³"""
        self.batch_size = 16
        self.num_epochs = 10
        self.learning_rate = 1e-4
        self.num_workers = 0
        self.max_memory_mb = 4000
        
    def _mac_set_balanced_config(self):
        """å¹³è¡¡é…ç½® - æ¨è–¦è¨­ç½®"""
        self.batch_size = 32
        self.num_epochs = 20
        self.learning_rate = 3e-4
        self.num_workers = 2
        self.max_memory_mb = 8000
        
    def _mac_set_performance_config(self):
        """æ€§èƒ½é…ç½® - é©åˆé«˜æ€§èƒ½Mac"""
        self.batch_size = 64
        self.num_epochs = 30
        self.learning_rate = 5e-4
        self.num_workers = 4
        self.max_memory_mb = 16000
        
    def _cuda_set_minimal_config(self):
        """æœ€å°é…ç½® - é©åˆè¨˜æ†¶é«”æœ‰é™çš„æƒ…æ³"""
        self.batch_size = 64
        self.num_epochs = 15
        self.learning_rate = 1e-4
        self.num_workers = 2
        self.max_memory_mb = 4096
        
    def _cuda_set_balanced_config(self):
        """å¹³è¡¡é…ç½® - æ¨è–¦è¨­ç½®"""
        self.batch_size = 128
        self.num_epochs = 20
        self.learning_rate = 3e-4
        self.num_workers = 4
        self.max_memory_mb = 8192
        
    def _cuda_set_performance_config(self):
        """æ€§èƒ½é…ç½® - é©åˆé«˜æ€§èƒ½Mac"""
        self.batch_size = 256
        self.num_epochs = 30
        self.learning_rate = 5e-4
        self.num_workers = 8
        self.max_memory_mb = 16384

# ==================== Backboneå®šç¾© ====================

class FashionBackbone(nn.Module):
    """å¯é…ç½®çš„Fashion Backbone"""
    def __init__(self, backbone_type='resnet50', pretrained=True):
        super(FashionBackbone, self).__init__()
        self.backbone_type = backbone_type
        
        if backbone_type == 'mobilenet':
            self.backbone = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1 if pretrained else None)
            self.backbone.classifier = nn.Identity()
            self.feature_dim = 960
            
        elif backbone_type == 'resnet18':
            self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)
            self.backbone.fc = nn.Identity()
            self.feature_dim = 512
            
        elif backbone_type == 'resnet50':
            self.backbone = timm.create_model("resnet50", pretrained=pretrained, num_classes=0)
            self.feature_dim = 2048
            
        elif backbone_type == 'efficientnet_b0':
            self.backbone = timm.create_model('efficientnet_b0', pretrained=pretrained, num_classes=0)
            self.feature_dim = 1280
            
        elif backbone_type == 'efficientnet_b2':
            self.backbone = timm.create_model('efficientnet_b2', pretrained=pretrained, num_classes=0)
            self.feature_dim = 1408
            
        elif backbone_type == 'vit_tiny':
            if pretrained:
                self.backbone = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=0)
            else:
                config = ViTConfig(hidden_size=192, num_hidden_layers=12, num_attention_heads=3)
                self.backbone = ViTModel(config)
            self.feature_dim = 192
            
        elif backbone_type == 'vit_small':
            if pretrained:
                self.backbone = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=0)
            else:
                config = ViTConfig(hidden_size=384, num_hidden_layers=12, num_attention_heads=6)
                self.backbone = ViTModel(config)
            self.feature_dim = 384
            
        elif backbone_type == 'fashion_resnet':
            self.backbone = self._create_fashion_resnet(pretrained)
            self.feature_dim = 512
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„backboneé¡å‹: {backbone_type}")
    
    def _create_fashion_resnet(self, pretrained):
        """å‰µå»ºé‡å°æ™‚å°šåœ–ç‰‡å„ªåŒ–çš„ResNet"""
        base_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)
        base_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        base_model.maxpool = nn.Identity()
        base_model.fc = nn.Identity()
        return base_model
    
    def forward(self, x):
        if 'vit' in self.backbone_type and hasattr(self.backbone, 'last_hidden_state'):
            outputs = self.backbone(x)
            if hasattr(outputs, 'last_hidden_state'):
                return outputs.last_hidden_state[:, 0, :]
            else:
                return outputs
        else:
            return self.backbone(x)
    
    def get_feature_dim(self):
        return self.feature_dim

# ==================== æ•¸æ“šé›† ====================

class UnsupervisedFashionDataset(Dataset):
    def __init__(self, data_root, config, transform=None):
        self.data_root = Path(data_root)
        self.config = config
        self.transform = transform
        self.invalid_images = []
        
        # æƒææ‰€æœ‰åœ–ç‰‡
        image_paths = list(self.data_root.rglob("*.[jJ][pP][gG]")) + \
                      list(self.data_root.rglob("*.[pP][nN][gG]")) + \
                      list(self.data_root.rglob("*.[aA][vV][iI][fF]"))
        
        self.image_paths = []
        for p in image_paths:
            try:
                with Image.open(p) as img:
                    img.verify()
                self.image_paths.append(str(p))
            except Exception as e:
                self.invalid_images.append(str(p))
                warnings.warn(f"ç„¡æ³•é©—è­‰åœ–ç‰‡ {p}: {e}")
        
        print(f"ğŸ“Š è¼‰å…¥äº† {len(self.image_paths)} å¼µæœ‰æ•ˆåœ–ç‰‡ï¼Œ{len(self.invalid_images)} å¼µç„¡æ•ˆåœ–ç‰‡")
        
        if self.invalid_images:
            with open("invalid_images.txt", "w") as f:
                f.write("\n".join(self.invalid_images))

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if image.size[0] < 10 or image.size[1] < 10:
                raise ValueError("åœ–ç‰‡å°ºå¯¸éå°")
        except Exception as e:
            warnings.warn(f"ç„¡æ³•è¼‰å…¥åœ–ç‰‡ {img_path}: {e}")
            image = Image.new('RGB', (224, 224), (128, 128, 128))
        
        if self.transform:
            image1 = self.transform(image)
            image2 = self.transform(image)
        else:
            image1 = image2 = transforms.ToTensor()(image)
        
        return image1, image2, img_path

# ==================== æ¨¡å‹å®šç¾© ====================

class UnsupervisedStyleModel(nn.Module):
    def __init__(self, config):
        super(UnsupervisedStyleModel, self).__init__()
        
        self.backbone = FashionBackbone(
            backbone_type=config.backbone_type, 
            pretrained=True
        )
        
        backbone_features = self.backbone.get_feature_dim()
        self.feature_dim = config.feature_dim
        
        # æŠ•å½±é ­ - ç”¨æ–¼å°æ¯”å­¸ç¿’
        self.projection = nn.Sequential(
            nn.Linear(backbone_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, config.feature_dim),
            nn.BatchNorm1d(config.feature_dim)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, (nn.BatchNorm1d, nn.LayerNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
        
    def forward(self, x):
        backbone_features = self.backbone(x)
        features = self.projection(backbone_features)
        return features

# ==================== æå¤±å‡½æ•¸ ====================

def nt_xent_loss(features1, features2, temperature):
    """
    NT-Xent (Normalized Temperature-scaled Cross Entropy) Loss for SimCLR
    ä¿®å¾©ç‰ˆæœ¬ï¼šæ­£ç¢ºå¯¦ç¾å°æ¯”å­¸ç¿’æå¤±
    """
    batch_size = features1.shape[0]
    device = features1.device
    
    # æª¢æŸ¥ç‰¹å¾µæ˜¯å¦å·²æ­¸ä¸€åŒ–
    features1 = F.normalize(features1, dim=1)
    features2 = F.normalize(features2, dim=1)
    
    # åˆä½µå…©å€‹viewçš„ç‰¹å¾µ: [2*batch_size, feature_dim]
    features = torch.cat([features1, features2], dim=0)
    
    # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£: [2*batch_size, 2*batch_size]
    similarity_matrix = torch.matmul(features, features.T) / temperature
    
    # å‰µå»ºæ­£æ¨£æœ¬æ©ç¢¼
    # å°æ–¼batchä¸­ç¬¬iå€‹æ¨£æœ¬ï¼Œæ­£æ¨£æœ¬å°æ˜¯ (i, i+batch_size) å’Œ (i+batch_size, i)
    labels = torch.arange(batch_size, device=device)
    # å‰µå»ºæ­£æ¨£æœ¬å°çš„æ¨™ç±¤
    positive_mask = torch.zeros(2 * batch_size, 2 * batch_size, device=device)
    for i in range(batch_size):
        positive_mask[i, i + batch_size] = 1  # view1 -> view2
        positive_mask[i + batch_size, i] = 1  # view2 -> view1
    
    # å‰µå»ºè² æ¨£æœ¬æ©ç¢¼ï¼ˆæ’é™¤è‡ªå·±å’Œæ­£æ¨£æœ¬ï¼‰
    negative_mask = torch.ones(2 * batch_size, 2 * batch_size, device=device)
    negative_mask = negative_mask - torch.eye(2 * batch_size, device=device)  # æ’é™¤è‡ªå·±
    negative_mask = negative_mask - positive_mask  # æ’é™¤æ­£æ¨£æœ¬
    
    # è¨ˆç®—æå¤±
    total_loss = 0.0
    num_positives = 0
    
    for i in range(2 * batch_size):
        # æ‰¾åˆ°æ­£æ¨£æœ¬
        positive_indices = torch.where(positive_mask[i] == 1)[0]
        if len(positive_indices) == 0:
            continue
            
        # è¨ˆç®—åˆ†å­ï¼šæ­£æ¨£æœ¬çš„ç›¸ä¼¼åº¦
        positive_similarities = similarity_matrix[i, positive_indices]
        
        # è¨ˆç®—åˆ†æ¯ï¼šæ‰€æœ‰è² æ¨£æœ¬çš„ç›¸ä¼¼åº¦
        negative_indices = torch.where(negative_mask[i] == 1)[0]
        if len(negative_indices) == 0:
            continue
            
        negative_similarities = similarity_matrix[i, negative_indices]
        
        # è¨ˆç®—InfoNCEæå¤±
        for pos_sim in positive_similarities:
            numerator = torch.exp(pos_sim)
            denominator = numerator + torch.sum(torch.exp(negative_similarities))
            
            if denominator > 0:
                loss = -torch.log(numerator / denominator)
                total_loss += loss
                num_positives += 1
    
    if num_positives > 0:
        return total_loss / num_positives
    else:
        return torch.tensor(0.0, device=device, requires_grad=True)

# ==================== è¨“ç·´å™¨ ====================

class OptimizedUnsupervisedTrainer:
    def __init__(self, model, config, device, output_dir):
        self.model = model
        self.config = config
        self.device = device
        self.output_dir = output_dir
        
        # å„ªåŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=config.learning_rate,
            weight_decay=1e-4
        )
        
        # å­¸ç¿’ç‡èª¿åº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=config.num_epochs
        )
        
        # è¨“ç·´è¨˜éŒ„
        self.train_history = {
            'epoch': [],
            'loss': [],
            'lr': [],
            'memory_usage': [],
            'temperature': [config.temperature]
        }
        
        # å‰µå»ºè¨“ç·´æ—¥èªŒæ–‡ä»¶
        self.log_file = os.path.join(output_dir, 'training_log.txt')
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write(f"ç„¡ç›£ç£è¨“ç·´é–‹å§‹æ™‚é–“: {datetime.now().isoformat()}\n")
            f.write(f"é…ç½®: {config.config_type}\n")
            f.write(f"Backbone: {config.backbone_type}\n")
            f.write("="*50 + "\n")
    
    def log_message(self, message):
        """è¨˜éŒ„è¨“ç·´æ—¥èªŒ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_msg + "\n")
    
    def get_memory_usage(self):
        """ç²å–è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024  # MB
    
    def train_epoch(self, dataloader, epoch):
        """è¨“ç·´ä¸€å€‹epoch"""
        self.model.train()
        total_loss = 0.0
        total_samples = 0
        
        for batch_idx, (images1, images2, _) in enumerate(dataloader):
            images1, images2 = images1.to(self.device), images2.to(self.device)
            
            self.optimizer.zero_grad()
            
            # å‰å‘å‚³æ’­
            features1 = self.model(images1)
            features2 = self.model(images2)
            
            # è¨ˆç®—å°æ¯”æå¤±
            loss = nt_xent_loss(features1, features2, self.config.temperature)
            
            # åå‘å‚³æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # çµ±è¨ˆ
            total_loss += loss.item()
            total_samples += images1.size(0)
            
            # è¨˜æ†¶é«”ç®¡ç†
            if batch_idx % 10 == 0:
                if hasattr(torch.cuda, 'empty_cache'):
                    torch.cuda.empty_cache()
                gc.collect()
            
            # é€²åº¦é¡¯ç¤º
            if batch_idx % 20 == 0:
                current_lr = self.optimizer.param_groups[0]['lr']
                memory_usage = self.get_memory_usage()
                
                self.log_message(
                    f"Epoch {epoch}/{self.config.num_epochs}, "
                    f"Batch {batch_idx}/{len(dataloader)}, "
                    f"Loss: {loss.item():.4f}, "
                    f"LR: {current_lr:.6f}, "
                    f"Memory: {memory_usage:.1f}MB"
                )
        
        # Epochçµ±è¨ˆ
        avg_loss = total_loss / len(dataloader)
        current_lr = self.optimizer.param_groups[0]['lr']
        memory_usage = self.get_memory_usage()
        
        # è¨˜éŒ„æ­·å²
        self.train_history['epoch'].append(epoch)
        self.train_history['loss'].append(avg_loss)
        self.train_history['lr'].append(current_lr)
        self.train_history['memory_usage'].append(memory_usage)
        
        self.log_message(
            f"Epoch {epoch} å®Œæˆ - "
            f"å¹³å‡æå¤±: {avg_loss:.4f}"
        )
        
        return avg_loss
    
    def save_checkpoint(self, epoch, loss, filename):
        """ä¿å­˜æª¢æŸ¥é»"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'loss': loss,
            'config': {
                'backbone_type': self.config.backbone_type,
                'feature_dim': self.config.feature_dim,
                'temperature': self.config.temperature
            }
        }
        
        filepath = os.path.join(self.output_dir, filename)
        torch.save(checkpoint, filepath)
        self.log_message(f"æª¢æŸ¥é»å·²ä¿å­˜: {filepath}")

def train_model(data_root, config_type="balanced", backbone_type="resnet50", resume_from=None, platform="cpu"):
    """ä¸»è¨“ç·´å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ç„¡ç›£ç£æ™‚å°šæ¨¡å‹è¨“ç·´")
    print("=" * 50)
    
    # è¨­å‚™è¨­ç½®
    device = torch.device("cpu")
    if platform == "auto":
        device = setup_cuda_optimization() # prefer cuda first
        if device == torch.device("cpu"):
            device = setup_mac_optimization()
    else:
        if platform == "cuda":
            device = setup_cuda_optimization()
        elif platform == "mps":
            device = setup_mac_optimization()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = create_output_directory()
    
    # å‰µå»ºé…ç½®
    config = TrainingConfig(config_type, backbone_type, device)
    save_config_to_file(config, output_dir)
    
    print(f"ğŸ“Š è¨“ç·´é…ç½®:")
    print(f"  é…ç½®é¡å‹: {config.config_type}")
    print(f"  Backbone: {config.backbone_type}")
    print(f"  æ‰¹æ¬¡å¤§å°: {config.batch_size}")
    print(f"  è¨“ç·´è¼ªæ•¸: {config.num_epochs}")
    print(f"  å­¸ç¿’ç‡: {config.learning_rate}")
    print(f"  æº«åº¦åƒæ•¸: {config.temperature}")
    
    # æ•¸æ“šé è™•ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # è¼‰å…¥æ•¸æ“šé›†
    print(f"ğŸ“‚ è¼‰å…¥æ•¸æ“šé›†: {data_root}")
    dataset = UnsupervisedFashionDataset(data_root, config, transform=transform)
    
    if not dataset.image_paths:
        raise ValueError("ç„¡æœ‰æ•ˆåœ–ç‰‡å¯è¨“ç·´")
    
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=True,
        num_workers=config.num_workers,
        pin_memory=False,
        drop_last=True
    )
    
    # å‰µå»ºæ¨¡å‹
    print(f"ğŸ”§ å‰µå»ºæ¨¡å‹: {config.backbone_type}")
    model = UnsupervisedStyleModel(config).to(device)
    
    # å‰µå»ºè¨“ç·´å™¨
    trainer = OptimizedUnsupervisedTrainer(model, config, device, output_dir)
    
    # æ¢å¾©è¨“ç·´ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    start_epoch = 1
    best_loss = float('inf')
    
    if resume_from and os.path.exists(resume_from):
        print(f"ğŸ“¥ æ¢å¾©è¨“ç·´: {resume_from}")
        checkpoint = torch.load(resume_from, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        trainer.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_loss = checkpoint['loss']
        trainer.log_message(f"å¾ epoch {start_epoch-1} æ¢å¾©è¨“ç·´")
    
    # è¨“ç·´å¾ªç’°
    trainer.log_message("é–‹å§‹è¨“ç·´å¾ªç’°")
    
    try:
        for epoch in range(start_epoch, config.num_epochs + 1):
            epoch_loss = trainer.train_epoch(dataloader, epoch)
            
            # å­¸ç¿’ç‡èª¿åº¦
            trainer.scheduler.step()
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if epoch_loss < best_loss:
                best_loss = epoch_loss
                trainer.save_checkpoint(
                    epoch, epoch_loss, 
                    f'best_model_{backbone_type}_{config_type}.pth'
                )
            
            # å®šæœŸä¿å­˜æª¢æŸ¥é»
            if epoch % 5 == 0:
                trainer.save_checkpoint(
                    epoch, epoch_loss,
                    f'checkpoint_epoch_{epoch}.pth'
                )
            
            # è¨˜æ†¶é«”æ¸…ç†
            if hasattr(torch.cuda, 'empty_cache'):
                torch.cuda.empty_cache()
            gc.collect()
    
    except KeyboardInterrupt:
        trainer.log_message("è¨“ç·´è¢«ä¸­æ–·")
        trainer.save_checkpoint(
            epoch, epoch_loss,
            f'interrupted_model_{backbone_type}_{config_type}.pth'
        )
    
    # ä¿å­˜æœ€çµ‚æ¨¡å‹
    trainer.save_checkpoint(
        config.num_epochs, best_loss,
        f'final_model_{backbone_type}_{config_type}.pth'
    )
    
    # ä¿å­˜è¨“ç·´æ­·å²
    save_training_history_plot(trainer.train_history, output_dir)
    
    # ä¿å­˜è¨“ç·´æ­·å²JSON
    history_path = os.path.join(output_dir, 'training_history.json')
    with open(history_path, 'w') as f:
        json.dump(trainer.train_history, f, indent=2)
    
    # æå–ç‰¹å¾µä¸¦ç”Ÿæˆdataset_labels.json
    trainer.log_message("æå–ç‰¹å¾µä¸¦ç”Ÿæˆdataset_labels.json")
    model.eval()
    dataset_labels = []
    
    with torch.no_grad():
        for images1, _, img_paths in dataloader:
            images1 = images1.to(device)
            features = model(images1).cpu().numpy()
            for path, feat in zip(img_paths, features):
                dataset_labels.append({
                    "path": path,
                    "unsupervised_features": feat.tolist()
                })
    
    labels_path = os.path.join(output_dir, 'dataset_labels.json')
    with open(labels_path, "w") as f:
        json.dump(dataset_labels, f, indent=2)
    trainer.log_message(f"å·²ç”Ÿæˆ dataset_labels.jsonï¼ŒåŒ…å« {len(dataset_labels)} æ¢è¨˜éŒ„")
    
    trainer.log_message("è¨“ç·´å®Œæˆï¼")
    print(f"\nâœ… è¨“ç·´å®Œæˆï¼")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print(f"ğŸ† æœ€ä½³æå¤±: {best_loss:.4f}")

def main():
    parser = argparse.ArgumentParser(description='æ™‚å°šç„¡ç›£ç£å­¸ç¿’è¨“ç·´ç³»çµ±')
    parser.add_argument('--data', type=str, default='../dataset',
                       help='æ•¸æ“šé›†æ ¹ç›®éŒ„')
    parser.add_argument('--config', type=str, default='balanced',
                       choices=['minimal', 'balanced', 'performance'],
                       help='è¨“ç·´é…ç½®é¡å‹')
    parser.add_argument('--backbone', type=str, default='resnet50',
                       choices=['mobilenet', 'resnet18', 'resnet50', 'efficientnet_b0', 
                               'efficientnet_b2', 'vit_tiny', 'vit_small', 'fashion_resnet'],
                       help='Backboneæ¶æ§‹')
    parser.add_argument('--resume', type=str, default=None,
                       help='æ¢å¾©è¨“ç·´çš„æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--platform', type=str, default='auto',
                        choices=['mps', 'cuda', 'cpu', 'auto'],
                        help='æ‰€ä½¿ç”¨çš„ç¡¬é«”è£ç½®')
    
    args = parser.parse_args()
    
    train_model(
        data_root=args.data,
        config_type=args.config,
        backbone_type=args.backbone,
        resume_from=args.resume,
        platform=args.platform
    )

if __name__ == "__main__":
    main() 