#!/usr/bin/env python3
"""
æ™ºèƒ½ç©¿æ­æ¨è–¦ç³»çµ± FastAPI æ‡‰ç”¨
æä¾›åŸºæ–¼å¤šæ¨¡æ…‹AIçš„ç©¿æ­åˆ†æå’Œæ¨è–¦æœå‹™
å„ªåŒ–ç‚ºç·šä¸Šæœå‹™å’Œç§»å‹•ç«¯æ‡‰ç”¨
"""

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import uuid
import asyncio
import logging
from datetime import datetime
import shutil
import json
from pathlib import Path

# å°å…¥æˆ‘å€‘çš„æ¨è–¦ç³»çµ±
from improved_recommender import ImprovedFashionRecommendationSystem

# è¨­ç½®æ—¥èªŒ - æ·»åŠ æ›´è©³ç´°çš„æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)

# å‰µå»ºFastAPIæ‡‰ç”¨
app = FastAPI(
    title="æ™ºèƒ½ç©¿æ­æ¨è–¦ç³»çµ± API",
    description="åŸºæ–¼å¤šæ¨¡æ…‹AIçš„æ™ºèƒ½ç©¿æ­åˆ†æèˆ‡æ¨è–¦æœå‹™ - ç§»å‹•ç«¯å„ªåŒ–ç‰ˆ",
    version="2.1.1",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSè¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²è¨­ç½®å…·é«”çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å‰µå»ºå¿…è¦çš„ç›®éŒ„
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# æ•¸æ“šé›†ç›®éŒ„è¨­ç½®
DATASET_DIR = Path("../dataset")
if not DATASET_DIR.exists():
    DATASET_DIR = Path("dataset")  # å‚™ç”¨è·¯å¾‘

# æ›è¼‰éœæ…‹æ–‡ä»¶
app.mount("/uploads", StaticFiles(directory="uploads"), name="uploads")

# æ›è¼‰æ•¸æ“šé›†éœæ…‹æ–‡ä»¶
if DATASET_DIR.exists():
    app.mount("/dataset", StaticFiles(directory=str(DATASET_DIR)), name="dataset")
    logger.info(f"ğŸ“ æ•¸æ“šé›†ç›®éŒ„æ›è¼‰: {DATASET_DIR.absolute()}")
else:
    logger.warning("âš ï¸ æ•¸æ“šé›†ç›®éŒ„ä¸å­˜åœ¨ï¼Œåœ–ç‰‡å¯èƒ½ç„¡æ³•é¡¯ç¤º")

# å…¨åŸŸæ¨è–¦ç³»çµ±å¯¦ä¾‹
recommendation_system = None

# è«‹æ±‚å’Œå›æ‡‰æ¨¡å‹
class RecommendationRequest(BaseModel):
    gender: str
    style_preference: Optional[str] = None
    top_k: int = 4
    strategy: str = "balanced"

class AdviceRequest(BaseModel):
    user_image_path: str
    target_image_path: str
    target_style: str
    ai_models: List[str] = ["rule_based", "clip"]

class DetailedSimilarity(BaseModel):
    visual_similarity: float
    main_component_similarity: float
    style_similarity: Optional[float] = None

class RecommendationItem(BaseModel):
    recommendation_id: str
    path: str
    style: str
    gender: str
    similarity: float
    score: float
    detailed_similarity: DetailedSimilarity

class QuickRecommendationResponse(BaseModel):
    status: str
    request_id: str
    input_image_url: str
    analysis_time: float
    recommendations: List[RecommendationItem]
    style_analysis: Dict[str, Any]

class AdviceResponse(BaseModel):
    status: str
    request_id: str
    recommendation_id: str
    target_style: str
    ai_advice: Dict[str, str]
    analysis_time: float

class FeatureAnalysis(BaseModel):
    top_feature: str
    score: float
    all_scores: Dict[str, float]

class ErrorResponse(BaseModel):
    status: str
    error: str
    request_id: str

# å•Ÿå‹•äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """æ‡‰ç”¨å•Ÿå‹•æ™‚åˆå§‹åŒ–æ¨è–¦ç³»çµ±"""
    global recommendation_system
    try:
        logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ç©¿æ­æ¨è–¦ç³»çµ±...")
        recommendation_system = ImprovedFashionRecommendationSystem()
        logger.info("âœ… æ¨è–¦ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æ¨è–¦ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        raise

# é—œé–‰äº‹ä»¶
@app.on_event("shutdown")
async def shutdown_event():
    """æ‡‰ç”¨é—œé–‰æ™‚çš„æ¸…ç†å·¥ä½œ"""
    logger.info("ğŸ”„ æ­£åœ¨é—œé–‰æ¨è–¦ç³»çµ±...")

def cleanup_old_files():
    """æ¸…ç†èˆŠæ–‡ä»¶"""
    try:
        # æ¸…ç†è¶…é2å°æ™‚çš„ä¸Šå‚³æ–‡ä»¶
        for file_path in UPLOAD_DIR.glob("*"):
            if file_path.is_file():
                file_age = datetime.now().timestamp() - file_path.stat().st_mtime
                if file_age > 7200:  # 2å°æ™‚
                    file_path.unlink()
    except Exception as e:
        logger.error(f"æ¸…ç†æ–‡ä»¶å¤±æ•—: {e}")

def convert_path_to_url(file_path: str) -> str:
    """è½‰æ›æª”æ¡ˆè·¯å¾‘ç‚ºURLè·¯å¾‘"""
    # è™•ç†ç›¸å°è·¯å¾‘
    if file_path.startswith("../dataset/"):
        # è½‰æ›ç‚º /dataset/ è·¯å¾‘
        return file_path.replace("../dataset/", "/dataset/")
    elif file_path.startswith("dataset/"):
        return "/" + file_path
    elif file_path.startswith("/dataset/"):
        return file_path
    else:
        # å¦‚æœæ˜¯çµ•å°è·¯å¾‘ï¼Œå˜—è©¦æå–ç›¸å°éƒ¨åˆ†
        if "dataset" in file_path:
            parts = file_path.split("dataset")
            if len(parts) > 1:
                return "/dataset" + parts[-1]
    
    # é è¨­è¿”å›åŸè·¯å¾‘
    return file_path

async def process_quick_recommendation(
    image_path: str,
    request_data: RecommendationRequest,
    request_id: str
) -> Dict[str, Any]:
    """å¿«é€Ÿæ¨è–¦è™•ç†é‚è¼¯ï¼ˆä¸åŒ…å«æ–‡å­—å»ºè­°ç”Ÿæˆï¼‰"""
    try:
        start_time = datetime.now()
        logger.info(f"ğŸ” é–‹å§‹è™•ç†æ¨è–¦è«‹æ±‚ {request_id}")
        logger.info(f"ğŸ“ è«‹æ±‚åƒæ•¸: æ€§åˆ¥={request_data.gender}, é¢¨æ ¼={request_data.style_preference}, ç­–ç•¥={request_data.strategy}")
        
        # åŸ·è¡Œå¿«é€Ÿæ¨è–¦åˆ†æï¼ˆä¸ä½¿ç”¨AIæ¨¡å‹ï¼‰
        similar_outfits = recommendation_system.find_similar_outfits_improved(
            image_path=image_path,
            gender=request_data.gender,
            top_k=request_data.top_k,
            style_preference=request_data.style_preference,
            similarity_weights=_get_strategy_weights(request_data.strategy)
        )
        
        if not similar_outfits:
            raise HTTPException(status_code=404, detail="æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼çš„ç©¿æ­")
        
        # ç”Ÿæˆé¢¨æ ¼åˆ†æ
        style_analysis = _generate_style_analysis(similar_outfits)
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        # è¼¸å‡ºæ¨è–¦çµæœåˆ°terminal
        logger.info("=" * 60)
        logger.info(f"ğŸ¯ æ¨è–¦åˆ†æå®Œæˆ (è«‹æ±‚ID: {request_id})")
        logger.info(f"â±ï¸  åˆ†ææ™‚é–“: {processing_time:.2f}ç§’")
        logger.info(f"ğŸ‘¤ ç›®æ¨™ç”¨æˆ¶: {request_data.gender}")
        logger.info(f"ğŸ¨ ä¸»è¦é¢¨æ ¼: {style_analysis.get('dominant_style', 'N/A')}")
        logger.info(f"ğŸ“Š å¹³å‡ç›¸ä¼¼åº¦: {style_analysis.get('average_visual_similarity', 0)*100:.1f}%")
        logger.info("")
        logger.info("ğŸ“¸ æ¨è–¦åœ–ç‰‡åˆ—è¡¨:")
        
        # æ ¼å¼åŒ–å›æ‡‰ï¼ˆæ·»åŠ recommendation_idå’ŒURLè½‰æ›ï¼‰
        recommendations = []
        for i, rec in enumerate(similar_outfits):
            recommendation_id = f"{request_id}_rec_{i}"
            
            # è½‰æ›è·¯å¾‘ç‚ºURL
            original_path = rec["path"]
            url_path = convert_path_to_url(original_path)
            
            # è¼¸å‡ºæ¯å€‹æ¨è–¦çš„è©³ç´°ä¿¡æ¯
            logger.info(f"  {i+1}. é¢¨æ ¼: {rec['style']}")
            logger.info(f"     åŸå§‹è·¯å¾‘: {original_path}")
            logger.info(f"     URLè·¯å¾‘: {url_path}")
            logger.info(f"     ç›¸ä¼¼åº¦: {rec['similarity']*100:.1f}%")
            logger.info(f"     è©•åˆ†: {rec['score']:.1f}/10")
            logger.info(f"     æ¨è–¦ID: {recommendation_id}")
            logger.info("")
            
            recommendations.append({
                "recommendation_id": recommendation_id,
                "path": url_path,  # ä½¿ç”¨è½‰æ›å¾Œçš„URLè·¯å¾‘
                "style": rec["style"],
                "gender": rec["gender"],
                "similarity": rec["similarity"],
                "score": rec["score"],
                "detailed_similarity": rec["detailed_similarity"]
            })
        
        # è¼¸å‡ºé¢¨æ ¼åˆ†ä½ˆ
        if 'style_distribution' in style_analysis:
            logger.info("ğŸ¨ é¢¨æ ¼åˆ†ä½ˆ:")
            for style, count in style_analysis['style_distribution'].items():
                logger.info(f"  - {style}: {count} å¼µ")
        
        logger.info("=" * 60)
        
        response_data = {
            "status": "success",
            "request_id": request_id,
            "input_image_url": f"/uploads/{os.path.basename(image_path)}",
            "analysis_time": processing_time,
            "recommendations": recommendations,
            "style_analysis": style_analysis
        }
        
        return response_data
        
    except Exception as e:
        logger.error(f"âŒ è™•ç†å¿«é€Ÿæ¨è–¦è«‹æ±‚å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def _get_strategy_weights(strategy: str) -> Dict[str, float]:
    """ç²å–ç­–ç•¥æ¬Šé‡"""
    strategy_weights = {
        'pure_visual': {'original': 1.0, 'pca': 0.0, 'mapped': 0.0},
        'balanced': {'original': 0.5, 'pca': 0.3, 'mapped': 0.2},
        'style_aware': {'original': 0.3, 'pca': 0.2, 'mapped': 0.5}
    }
    return strategy_weights.get(strategy, strategy_weights['balanced'])

def _generate_style_analysis(similar_outfits: List[Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆé¢¨æ ¼åˆ†æ"""
    if not similar_outfits:
        return {}
    
    style_distribution = {}
    visual_similarities = []
    style_similarities = []
    
    for outfit in similar_outfits:
        style = outfit['style']
        style_distribution[style] = style_distribution.get(style, 0) + 1
        visual_similarities.append(outfit['detailed_similarity']['visual_similarity'])
        if 'style_similarity' in outfit['detailed_similarity']:
            style_similarities.append(outfit['detailed_similarity']['style_similarity'])
    
    dominant_style = max(style_distribution.items(), key=lambda x: x[1])[0]
    
    return {
        "dominant_style": dominant_style,
        "style_distribution": style_distribution,
        "average_visual_similarity": float(sum(visual_similarities) / len(visual_similarities)),
        "average_style_similarity": float(sum(style_similarities) / len(style_similarities)) if style_similarities else 0,
        "max_visual_similarity": float(max(visual_similarities))
    }

async def process_advice_generation(
    user_image_path: str,
    target_image_path: str,
    target_style: str,
    ai_models: List[str],
    request_id: str
) -> Dict[str, str]:
    """ç”Ÿæˆç‰¹å®šæ¨è–¦çš„AIå»ºè­°"""
    try:
        logger.info(f"ğŸ¤– é–‹å§‹ç”ŸæˆAIå»ºè­° (è«‹æ±‚ID: {request_id})")
        logger.info(f"ğŸ¯ ç›®æ¨™é¢¨æ ¼: {target_style}")
        logger.info(f"ğŸ§  ä½¿ç”¨æ¨¡å‹: {', '.join(ai_models)}")
        
        # è¼‰å…¥æ‰€éœ€çš„AIæ¨¡å‹
        recommendation_system._load_ai_models(ai_models)
        
        # å‰µå»ºæ¨¡æ“¬æ¨è–¦å°è±¡
        recommendation = {
            'path': target_image_path,
            'style': target_style,
            'similarity': 0.8  # æ¨¡æ“¬ç›¸ä¼¼åº¦
        }
        
        # ç”Ÿæˆå»ºè­°
        advice_results = {}
        
        for model_key in ai_models:
            if model_key in recommendation_system.loaded_ai_models or model_key in ['rule_based', 'clip']:
                try:
                    logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨ {model_key} æ¨¡å‹ç”Ÿæˆå»ºè­°...")
                    advice = recommendation_system._generate_model_advice(
                        model_key, user_image_path, recommendation
                    )
                    advice_results[model_key] = advice
                    logger.info(f"âœ… {model_key} æ¨¡å‹å»ºè­°ç”Ÿæˆå®Œæˆ")
                except Exception as e:
                    logger.error(f"âŒ {model_key} æ¨¡å‹å»ºè­°ç”Ÿæˆå¤±æ•—: {str(e)}")
                    advice_results[model_key] = f"ç”Ÿæˆå¤±æ•—: {str(e)}"
            else:
                advice_results[model_key] = "æ¨¡å‹æœªè¼‰å…¥"
        
        # è¼¸å‡ºå»ºè­°çµæœ
        logger.info("ğŸ“ AIå»ºè­°ç”Ÿæˆçµæœ:")
        for model, advice in advice_results.items():
            logger.info(f"  ğŸ¤– {model}: {advice[:100]}..." if len(advice) > 100 else f"  ğŸ¤– {model}: {advice}")
        
        return advice_results
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå»ºè­°å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/", tags=["åŸºæœ¬ä¿¡æ¯"])
async def root():
    """APIæ ¹ç«¯é»"""
    return {
        "message": "æ™ºèƒ½ç©¿æ­æ¨è–¦ç³»çµ± API - ç§»å‹•ç«¯å„ªåŒ–ç‰ˆ",
        "version": "2.1.1",
        "status": "é‹è¡Œä¸­",
        "docs": "/docs",
        "features": [
            "å¿«é€Ÿæ¨è–¦æŸ¥æ‰¾",
            "åˆ†é›¢å¼AIå»ºè­°ç”Ÿæˆ",
            "Fashion-CLIP ç‰¹å¾µåˆ†æ",
            "ç§»å‹•ç«¯å„ªåŒ–",
            "åœ–ç‰‡è·¯å¾‘ä¿®å¾©"
        ]
    }

@app.get("/health", tags=["å¥åº·æª¢æŸ¥"])
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    try:
        system_status = "healthy" if recommendation_system else "unavailable"
        return {
            "status": "ok",
            "system": system_status,
            "timestamp": datetime.now().isoformat(),
            "dataset_mounted": DATASET_DIR.exists()
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"æœå‹™ä¸å¯ç”¨: {str(e)}")

@app.post("/recommend", response_model=QuickRecommendationResponse, tags=["å¿«é€Ÿæ¨è–¦"])
async def quick_recommend(
    background_tasks: BackgroundTasks,
    image: UploadFile = File(..., description="ç©¿æ­åœ–ç‰‡æ–‡ä»¶"),
    gender: str = Form(..., description="æ€§åˆ¥ (MEN/WOMEN)"),
    style_preference: Optional[str] = Form(None, description="é¢¨æ ¼åå¥½ (å¯é¸)"),
    top_k: int = Form(4, description="æ¨è–¦æ•¸é‡"),
    strategy: str = Form("balanced", description="æ¨è–¦ç­–ç•¥")
):
    """
    å¿«é€Ÿæ¨è–¦ç«¯é» - åªè¿”å›æ¨è–¦åˆ—è¡¨ï¼Œä¸ç”ŸæˆAIå»ºè­°
    
    é©åˆç§»å‹•ç«¯æ‡‰ç”¨çš„å¿«é€ŸéŸ¿æ‡‰æ¥å£
    - **image**: ä¸Šå‚³çš„ç©¿æ­åœ–ç‰‡
    - **gender**: æ€§åˆ¥é¸æ“‡ (MEN æˆ– WOMEN)
    - **style_preference**: é¢¨æ ¼åå¥½ (å¯é¸: CASUAL, STREET, FORMAL, BOHEMIAN)
    - **top_k**: æ¨è–¦æ•¸é‡ (1-10)
    - **strategy**: æ¨è–¦ç­–ç•¥ (pure_visual, balanced, style_aware)
    """
    
    # ç”Ÿæˆè«‹æ±‚ID
    request_id = str(uuid.uuid4())
    
    try:
        logger.info(f"ğŸ“¥ æ”¶åˆ°æ–°çš„æ¨è–¦è«‹æ±‚ (ID: {request_id})")
        logger.info(f"ğŸ“‹ æª”æ¡ˆåç¨±: {image.filename}")
        logger.info(f"ğŸ“‹ æª”æ¡ˆå¤§å°: {image.size if hasattr(image, 'size') else 'N/A'} bytes")
        logger.info(f"ğŸ“‹ å…§å®¹é¡å‹: {image.content_type}")
        
        # é©—è­‰è¼¸å…¥
        if gender not in ["MEN", "WOMEN"]:
            raise HTTPException(status_code=400, detail="æ€§åˆ¥å¿…é ˆæ˜¯ MEN æˆ– WOMEN")
        
        if not (1 <= top_k <= 10):
            raise HTTPException(status_code=400, detail="æ¨è–¦æ•¸é‡å¿…é ˆåœ¨ 1-10 ä¹‹é–“")
        
        if strategy not in ["pure_visual", "balanced", "style_aware"]:
            raise HTTPException(status_code=400, detail="ç„¡æ•ˆçš„æ¨è–¦ç­–ç•¥")
        
        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        if not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é ˆæ˜¯åœ–ç‰‡æ ¼å¼")
        
        # ä¿å­˜ä¸Šå‚³çš„åœ–ç‰‡
        file_extension = os.path.splitext(image.filename)[1]
        if not file_extension:
            file_extension = ".jpg"
        
        filename = f"{request_id}{file_extension}"
        file_path = UPLOAD_DIR / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(image.file, buffer)
        
        logger.info(f"ğŸ’¾ åœ–ç‰‡å·²ä¿å­˜: {file_path}")
        
        # å‰µå»ºè«‹æ±‚å°è±¡
        request_data = RecommendationRequest(
            gender=gender,
            style_preference=style_preference,
            top_k=top_k,
            strategy=strategy
        )
        
        # è™•ç†å¿«é€Ÿæ¨è–¦è«‹æ±‚
        result = await process_quick_recommendation(str(file_path), request_data, request_id)
        
        # æ·»åŠ å¾Œå°æ¸…ç†ä»»å‹™
        background_tasks.add_task(cleanup_old_files)
        
        logger.info(f"âœ… æ¨è–¦è«‹æ±‚è™•ç†å®Œæˆ (ID: {request_id})")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¿«é€Ÿæ¨è–¦å¤±æ•— (è«‹æ±‚ID: {request_id}): {e}")
        return ErrorResponse(
            status="error",
            error=str(e),
            request_id=request_id
        )

@app.post("/advice", response_model=AdviceResponse, tags=["AIå»ºè­°ç”Ÿæˆ"])
async def generate_advice(
    user_image_path: str = Form(..., description="ç”¨æˆ¶åœ–ç‰‡è·¯å¾‘"),
    target_image_path: str = Form(..., description="ç›®æ¨™æ¨è–¦åœ–ç‰‡è·¯å¾‘"),
    target_style: str = Form(..., description="ç›®æ¨™é¢¨æ ¼"),
    ai_models: str = Form("rule_based,clip", description="AIæ¨¡å‹åˆ—è¡¨ï¼Œç”¨é€—è™Ÿåˆ†éš”"),
    recommendation_id: str = Form(..., description="æ¨è–¦ID")
):
    """
    ç”Ÿæˆç‰¹å®šæ¨è–¦çš„AIå»ºè­°
    
    ç‚ºç‰¹å®šçš„æ¨è–¦é …ç›®ç”Ÿæˆè©³ç´°çš„ç©¿æ­å»ºè­°
    - **user_image_path**: ç”¨æˆ¶åœ–ç‰‡çš„ç›¸å°è·¯å¾‘
    - **target_image_path**: ç›®æ¨™æ¨è–¦åœ–ç‰‡è·¯å¾‘
    - **target_style**: ç›®æ¨™é¢¨æ ¼
    - **ai_models**: ä½¿ç”¨çš„AIæ¨¡å‹ (rule_based, clip, llava, blip2, instructblip)
    - **recommendation_id**: ä¾†è‡ªæ¨è–¦éŸ¿æ‡‰çš„recommendation_id
    """
    
    request_id = str(uuid.uuid4())
    
    try:
        start_time = datetime.now()
        logger.info(f"ğŸ¯ æ”¶åˆ°å»ºè­°ç”Ÿæˆè«‹æ±‚ (ID: {request_id})")
        logger.info(f"ğŸ“¸ æ¨è–¦ID: {recommendation_id}")
        
        # è§£æAIæ¨¡å‹åˆ—è¡¨
        model_list = [model.strip() for model in ai_models.split(",")]
        valid_models = ["rule_based", "clip", "llava", "blip2", "instructblip"]
        
        for model in model_list:
            if model not in valid_models:
                raise HTTPException(
                    status_code=400, 
                    detail=f"ç„¡æ•ˆçš„AIæ¨¡å‹: {model}. æœ‰æ•ˆé¸é …: {', '.join(valid_models)}"
                )
        
        # æ§‹å»ºå®Œæ•´çš„ç”¨æˆ¶åœ–ç‰‡è·¯å¾‘
        if user_image_path.startswith("/uploads/"):
            full_user_image_path = user_image_path[9:]  # ç§»é™¤ /uploads/ å‰ç¶´
        else:
            full_user_image_path = user_image_path
        
        full_user_image_path = UPLOAD_DIR / full_user_image_path
        
        if not full_user_image_path.exists():
            raise HTTPException(status_code=404, detail="ç”¨æˆ¶åœ–ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è™•ç†ç›®æ¨™åœ–ç‰‡è·¯å¾‘ - è½‰æ›URLè·¯å¾‘å›æª”æ¡ˆè·¯å¾‘
        if target_image_path.startswith("/dataset/"):
            # å¾URLè·¯å¾‘è½‰æ›ç‚ºå¯¦éš›æª”æ¡ˆè·¯å¾‘
            actual_target_path = DATASET_DIR / target_image_path[9:]  # ç§»é™¤ /dataset/ å‰ç¶´
        else:
            actual_target_path = Path(target_image_path)
        
        if not actual_target_path.exists():
            logger.error(f"âŒ ç›®æ¨™åœ–ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {actual_target_path}")
            raise HTTPException(status_code=404, detail="ç›®æ¨™åœ–ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ç”ŸæˆAIå»ºè­°
        advice_results = await process_advice_generation(
            str(full_user_image_path),
            str(actual_target_path),
            target_style,
            model_list,
            request_id
        )
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        logger.info(f"âœ… å»ºè­°ç”Ÿæˆå®Œæˆ (ID: {request_id}, è€—æ™‚: {processing_time:.2f}ç§’)")
        
        return AdviceResponse(
            status="success",
            request_id=request_id,
            recommendation_id=recommendation_id,
            target_style=target_style,
            ai_advice=advice_results,
            analysis_time=processing_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå»ºè­°å¤±æ•— (è«‹æ±‚ID: {request_id}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/extract-features", tags=["ç‰¹å¾µæå–"])
async def extract_features(
    image: UploadFile = File(..., description="ç©¿æ­åœ–ç‰‡æ–‡ä»¶")
):
    """
    æå–åœ–ç‰‡çš„è©³ç´°æ™‚å°šç‰¹å¾µ
    
    è¿”å›8å¤§é¡ç‰¹å¾µçš„è©³ç´°åˆ†æï¼šé¡è‰²ã€æœè£é¡å‹ã€é¢¨æ ¼ã€åœ–æ¡ˆã€é…é£¾ã€é‹é¡ã€æè³ªã€ç‰ˆå‹
    """
    
    request_id = str(uuid.uuid4())
    
    try:
        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        if not image.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é ˆæ˜¯åœ–ç‰‡æ ¼å¼")
        
        # ä¿å­˜ä¸Šå‚³çš„åœ–ç‰‡
        file_extension = os.path.splitext(image.filename)[1] or ".jpg"
        filename = f"{request_id}{file_extension}"
        file_path = UPLOAD_DIR / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(image.file, buffer)
        
        # æå–ç‰¹å¾µ
        features = recommendation_system.extract_detailed_fashion_features(str(file_path))
        
        if not features:
            raise HTTPException(status_code=500, detail="ç‰¹å¾µæå–å¤±æ•—")
        
        return {
            "status": "success",
            "request_id": request_id,
            "features": features,
            "categories": list(features.keys()),
            "summary": {
                "ç¸½ç‰¹å¾µé¡åˆ¥": len(features),
                "æœ€é«˜ä¿¡å¿ƒåº¦": max(data["score"] for data in features.values()),
                "ä¸»è¦ç‰¹å¾µ": {category: data["top_feature"] for category, data in features.items()}
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ç‰¹å¾µæå–å¤±æ•— (è«‹æ±‚ID: {request_id}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/models", tags=["ç³»çµ±ä¿¡æ¯"])
async def get_available_models():
    """ç²å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨"""
    return {
        "available_models": {
            "rule_based": {
                "name": "è¦å‰‡ç³»çµ±",
                "description": "åŸºæ–¼é è¨­è¦å‰‡çš„ç©¿æ­å»ºè­°",
                "speed": "å¿«",
                "accuracy": "ä¸­ç­‰"
            },
            "clip": {
                "name": "FashionCLIP",
                "description": "Fashion-CLIP è©³ç´°ç‰¹å¾µåˆ†æ",
                "speed": "å¿«",
                "accuracy": "é«˜"
            },
            "llava": {
                "name": "è¦–è¦ºèªè¨€æ¨¡å‹",
                "description": "LLaVA é›™åœ–ç‰‡æ¯”è¼ƒåˆ†æ",
                "speed": "æ…¢",
                "accuracy": "æ¥µé«˜"
            },
            "blip2": {
                "name": "åœ–åƒæè¿°æ¨¡å‹",
                "description": "BLIP-2 åœ–åƒç†è§£å’Œæè¿°",
                "speed": "ä¸­ç­‰",
                "accuracy": "é«˜"
            },
            "instructblip": {
                "name": "æŒ‡ä»¤åœ–åƒæ¨¡å‹",
                "description": "InstructBLIP æŒ‡ä»¤å¼åœ–åƒåˆ†æ",
                "speed": "ä¸­ç­‰",
                "accuracy": "é«˜"
            }
        },
        "strategies": {
            "pure_visual": "ç´”è¦–è¦ºç›¸ä¼¼æ€§æ¨è–¦",
            "balanced": "å¹³è¡¡è¦–è¦ºå’Œé¢¨æ ¼çš„æ¨è–¦",
            "style_aware": "é¢¨æ ¼å°å‘çš„æ¨è–¦"
        },
        "supported_styles": [
            "CASUAL", "STREET", "FORMAL", "BOHEMIAN"
        ]
    }

@app.get("/stats", tags=["ç³»çµ±çµ±è¨ˆ"])
async def get_system_stats():
    """ç²å–ç³»çµ±çµ±è¨ˆä¿¡æ¯"""
    try:
        upload_count = len(list(UPLOAD_DIR.glob("*")))
        
        return {
            "status": "active",
            "upload_files": upload_count,
            "dataset_available": DATASET_DIR.exists(),
            "dataset_path": str(DATASET_DIR.absolute()),
            "system_info": {
                "dataset_size": len(recommendation_system.dataset) if recommendation_system else 0,
                "feature_categories": 8,
                "supported_models": 5,
                "supported_strategies": 3
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å•Ÿå‹•æ™ºèƒ½ç©¿æ­æ¨è–¦ç³»çµ± API æœå‹™å™¨ - ç§»å‹•ç«¯å„ªåŒ–ç‰ˆ v2.1.1")
    print("ğŸ“– API æ–‡æª”: http://localhost:8000/docs")
    print("ğŸ” API æ¸¬è©¦: http://localhost:8000/redoc")
    print(f"ğŸ“ æ•¸æ“šé›†è·¯å¾‘: {DATASET_DIR.absolute()}")
    
    uvicorn.run(
        "app:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    ) 